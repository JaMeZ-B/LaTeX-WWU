%!TEX root = ../LA2.tex
\section{Die Jordan-Normalform}
\label{sec:2.9}

In diesem Abschnitt wollen wir Endomorphismen untersuchen, die nicht unbedingt diagonalisierbar sind.
Wir werden sehen, dass in vielen Fällen eine etwas schwächere Normalform der Darstellungsmatrix von $F$ möglich ist, die zum Beispiel immer noch ermöglicht, den Endomorphismus $\exp(F)$ für $F \in \End_{\CC}(V)$ bzw. $\exp(A)$ für $A \in M(n \times n, \CC)$ zu berechnen.
Wir werden diese Normalform dann später benutzen, um Differentialgleichungen zu lösen.
Wir starten mit:

\begin{definition}[trigonalisierbar]
	\mbox{} \\[-1.4cm]
	\label{def:9.1}
	\begin{enumerate}[(i)]
		\item Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
		Dann heißt $F$ \Index{trigonalisierbar}, falls eine Basis $B = \{v_1,\dots,v_n\}$ von $V$ existiert, sodass die Darstellungsmatrix $A_F^B$ von $F$ bezüglich $B$ eine obere Dreiecksmatrix ist, das heißt für geeignete $\lambda_1,\dots,\lambda_n \in K$ gilt
		\[
			A_F^B = \begin{pmatrix}
			\lambda_1 & * & \cdots & * \\ 
			0 & \lambda_2 & \cdots & * \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda_n
			\end{pmatrix}. 
		\]
		\item Ist $A \in M(n \times n, K)$, so heißt $A$ \Index{trigonalisierbar}, falls ein $S \in \GL(n,K)$ existiert, sodass $S^{-1}AS$ eine obere Dreiecksmatrix ist.
	\end{enumerate}
\end{definition}

\begin{bemerkung}
	\mbox{} \\[-1.4cm]
	\label{bem:9.2}
	\begin{enumerate}[(i)]
		\item Ist $F \in \End_K(V)$ und $A \in M(n \times n,K)$ eine beliebige Darstellungsmatrix von $F$, so gilt:
		\[
			F \text{ ist trigonalisierbar} \quad \Leftrightarrow \quad A \text{ ist trigonalisierbar.}
		\]
		\item Ist $F$ (bzw. $A$) trigonalisierbar, so folgt für das charakteristische Polynom $\chi_F$ (und ähnlich für $\chi_A$), dass
		\[
			\chi_F(T) = \det(TE_n-A_F^B) = \det \begin{pmatrix}
			T-\lambda_1 & * & \cdots & * \\ 
			0 & T-\lambda_2 & \cdots & * \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & T-\lambda_n
			\end{pmatrix} = \prod\limits_{i=1}^{n} (T-\lambda_i).
		\]
		Wir sehen also, dass $\chi_F$ in Linearfaktoren zerfällt und die Diagonalelemente $\lambda_i$ von $A^B_F$ sind gerade die Eigenwerte von $F$.
		\item Aus (ii) folgt:
		Die Matrix $A = \begin{pmatrix}
			0 & 1 \\ -1 & 0
		\end{pmatrix} \in M(2 \times 2,\RR)$ ist nicht trigonalisierbar, da $\chi_A(T) = T^2 +1$ über $\RR$ nicht in Linearfaktoren zerfällt.
		Fassen wir $A$ aber als komplexe Matrix auf, so ist $A$ sogar diagonalisierbar.
		Wir sehen, dass es für diese Fragen ganz wichtig ist, über welchem Körper $K$ wir arbeiten!
	\end{enumerate}
\end{bemerkung}
\newpage
Die Beobachtung in (ii) besitzt auch eine Umkehrung:

\begin{satz}
	\label{satz:9.3}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
	Dann sind äquivalent:
	\begin{enumerate}[(i)]
		\item	$F$ ist diagonalisierbar.
		\item Das charakteristische Polynom $\chi_F$ von $F$ zerfällt in Linearfaktoren.
	\end{enumerate}
\end{satz}

\begin{bemerkung}
	\label{bem:9.4}
	Nach dem Fundamentalsatz der Algebra (\autoref{satz:1.11}) zerfällt jedes komplexe Polynom in Linearfaktoren.
	Aus \autoref{satz:9.3} folgt also insbesondere, dass jedes $F \in \End_{\CC}(V)$ trigonalisierbar ist, wenn $V$ ein endlich dimensionaler $\CC$-Vektorraum ist.
	Allgemeiner gilt:
	Ist $K$ ein \textbf{algebraisch abgeschlossener} Körper (das heißt, dass jedes Polynom über $K$ in Linearfaktoren zerfällt), und ist $V$ ein endlich dimensionaler $K$-Vektorraum, so ist jedes $F \in \End_K(V)$ trigonalisierbar. \index{algebraisch abgeschlossen}
\end{bemerkung}

Die Richtung (i) $\Rightarrow$ (ii) des Satzes folgt aus \autoref{bem:9.2}(ii).
Die andere Richtung werden wir in \autoref{satz:9.6} beweisen, wobei wir auch zeigen werden, dass die gesuche obere Dreiecksmatrix in einer besonderen Form gewählt werden kann.
Wir starten mit:

\begin{definition}[Jordan-Normalform]
	\mbox{} \\[-1.4cm]
	\label{def:9.5}
	\begin{enumerate}[(i)]
		\item Eine Matrix $J \in M(m \times m, K)$ heißt \Index{Jordan-Kasten}, falls ein $\lambda \in K$ existiert mit
		\[
			J = \begin{pmatrix}
			\lambda & 1 & 0 & \cdots & 0 \\ 
			0 & \lambda & 1 & \cdots & 0 \\ 
			\vdots &  & \ddots & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda & 1 \\ 
			0 & \cdots & \cdots & 0 & \lambda
			\end{pmatrix}.
		\]
		Wir sagen dann auch, dass $J$ ein $\lambda$-Jordan-Kasten der Länge $m$ ist.
		\item Eine Matrix $A \in M(n \times n,K)$ heißt \textbf{in Jordan-Normalform} (oder einfach nur \Index{Jordan-Matrix}), falls \index{Jordan-Normalform}
		\[
			A = \begin{pmatrix}
			J_1 & 0 & \cdots & 0 \\ 
			0 & J_2 & \cdots & 0 \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & J_r
			\end{pmatrix}, \text{ sodass }
			J_i = \begin{pmatrix}
			\lambda_i & 1 & 0 & \cdots & 0 \\ 
			0 & \lambda_i & 1 & \cdots & 0 \\ 
			\vdots &  & \ddots & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda_i & 1 \\ 
			0 & \cdots & \cdots & 0 & \lambda_i
			\end{pmatrix} \in M(k_i \times k_i,K)
		\]
		für alle $1 \leq i \leq r$ ein Jordan-Kasten ist.
	\end{enumerate}
\end{definition}

Beachte:
\begin{enumerate}[(i)]
	\item Jede $1 \times 1$-Matrix ist ein Jordan-Kasten der Länge $1$, und damit ist auch jede Diagonalmatrix eine Jordan-Matrix.
	\item Die Eigenwerte $\lambda_i$ der Jordan-Kästen $J_i$ von $A$ müssen nicht paarweise verschieden sein!
	Ein konkretes Beispiel für eine Jordan-Matrix ist gegeben durch
	\[ 
	a = \enb{\begin{BMAT}(b){cccccccc}{cccccccc}
	2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 2 & 1 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 2 & 1 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 0 & 3 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 0 & 0 & 3 & 1 \\ 
	0 & 0 & 0 & 0 & 0 & 0 & 0 & 3 
	\addpath{(0,8,|)rrrdddllluuu}
	\addpath{(3,5,|)rrddlluu}
	\addpath{(5,3,|)rdlu}
	\addpath{(6,2,|)rrddlluu}
	\end{BMAT}} = \begin{pmatrix}
		J_1 & 0 & 0 & 0 \\
		0 & J_2 & 0 & 0 \\
		0 & 0 & J_3 & 0 \\
		0 & 0 & 0 & J_4
	\end{pmatrix}
	\]
	mit den Jordan-Kästen
	\[
		J_1 = \begin{pmatrix}
			2 & 1 & 0 \\
			0 & 2 & 1 \\
			0 & 0 & 2
		\end{pmatrix}, J_2 = \begin{pmatrix}
			2 & 1 \\
			0 & 2
		\end{pmatrix}, J_3 = \begin{pmatrix}
		 3
		\end{pmatrix}, J_4 = \begin{pmatrix}
			3 & 1 \\
			0 & 3
		\end{pmatrix}.
	\]
\end{enumerate}

Im Rest dieses Abschnitts werden wir den folgenden Satz beweisen.
Als direkte Folgerung erhalten wir dann auch einen Beweis von \autoref{satz:9.3}.

\begin{satz}[Jordan-Normalform]
	\label{satz:9.6}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$ so, dass das charakteristische Polynom $\chi_F$ von $F$ in Linearfaktoren zerfällt.
	Dann existiert eine Basis $B = \{v_1,\dots,v_n\}$ von $V$, sodass $A_F^B$ eine Jordan-Matrix ist.
	
	Analog: Ist $A \in M(n \times n, K)$ so, dass $\chi_A$ in Linearfaktoren zerfällt, dann existiert ein $S \in \GL(n,K)$, sodass $S^{-1}AS$ eine Jordan-Matrix ist.
\end{satz}

Wie üblich folgt der zweite Teil des Satzes direkt aus dem ersten Teil, wenn wir den Endomorphismus $F_A \colon K^n \rightarrow K^n, x \mapsto Ax$ betrachten und die Elemente der Basis $B$ von $K^n$ wie im ersten Teil des Satzes als Spalten der Matrix $S$ nehmen.

Für den Beweis des Satzes benötigen wir einige Vorbereitungen.

\begin{lemma}[Direkte Summen von Endomorphismen und Blockmatrizen]
	\label{def:9.7}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
	Ist $V_1 \subseteq V$ mit $F(V_1) = V_1$, so können wir einen Endomorphismus $F_1 \in \End_K(V_1)$ durch $F_1(v) := F(v)$ für $v \in V_1$ definieren (also $F_1 = F \big|_{V_1} \colon V_1 \rightarrow V_1$).
	Besitzt $V$ eine direkte Summenzerlegung $V = V_1 \oplus V_2$ mit $F(V_1) \subseteq V_1$ und $F(V_2) \subseteq V_2$, so erhalten wir zwei Endomorphismen $F_1 \in \End_K(V_1)$ und $F_2 \in \End_K(V_2)$, und für jedes $v = v_1 + v_2 \in V$ mit $v_1 \in V_1, v_2 \in V_2$ gilt dann
	\[
		F(v) = F_1(v_1) + F_2(v_2).
	\]
	Wir sagen dann: $F$ ist die \Index{direkte Summe} von $F_1$ und $F_2$ und wir schreiben $F = F_1 \oplus F_2$.
	Sei nun $B_1 = \{v_1,\dots,v_r\}$ eine Basis von $V_1$ und $B_2 = \{v_{r+1},\dots,v_n\}$ eine Basis von $V_2$.
	Dann ist \linebreak $B := \{v_1,\dots,v_r,v_{r+1},\dots,v_n\}$ eine Basis von $V$ und für jedes $v_j$ aus dieser Basis gilt
	\[
	F(v_j) = \begin{cases}
	F_1(v_j) = \sum_{i=1}^{r} a_{ij} v_i, & \text{ falls } j \leq r \\
	F_2(v_j) = \sum_{i=r+1}^{n} a_{ij} v_i, & \text{ falls } r < j.
	\end{cases}
	\]
	Dann hat die Darstellungsmatrix $A := A_F^B$ von $F$ die Gestalt
	\[
	A = \begin{pmatrix}
	A_1 & 0 \\
	0 & A_2
	\end{pmatrix}, \text{ mit } A_1 = A_{F_1}^{B_1} \text{ und } A_2 = A_{F_2}^{B_2}.
	\]
	Sei umgekehrt $F$ ein beliebiger Endomorphismus von $V$, sodass eine Basis $B = \{v_1,\dots, v_r,v_{r+1},\dots,v_n\}$ von $V$ existiert mit $A_F^B = \begin{pmatrix}
	A_1 & 0 \\
	0 & A_2
	\end{pmatrix}$.
	Setzen wir dann $V_1 := \LH\{v_1,\dots,v_r\}$ und $V_2 := \{v_{r+1},\dots,v_n\}$, so folgt $V = V_1 \oplus V_2$ mit $F(V_i) \subseteq V_i$, also $F = F_1 \oplus F_2$ mit $F_i := F\big|_{V_i} \colon V_i \rightarrow V_i$ wie oben.
\end{lemma}

Wir benötigen:
\newpage