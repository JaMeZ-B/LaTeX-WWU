%!TEX root = ../LA2.tex
\section{Die Jordan-Normalform}
\label{sec:2.9}

In diesem Abschnitt wollen wir Endomorphismen untersuchen, die nicht unbedingt diagonalisierbar sind.
Wir werden sehen, dass in vielen Fällen eine etwas schwächere Normalform der Darstellungsmatrix von $F$ möglich ist, die zum Beispiel immer noch ermöglicht, den Endomorphismus $\exp(F)$ für $F \in \End_{\CC}(V)$ bzw. $\exp(A)$ für $A \in M(n \times n, \CC)$ zu berechnen.
Wir werden diese Normalform dann später benutzen, um Differentialgleichungen zu lösen.
Wir starten mit:

\begin{definition}[trigonalisierbar]
	\mbox{} \\[-1.4cm]
	\label{def:9.1}
	\begin{enumerate}[(i)]
		\item Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
		Dann heißt $F$ \Index{trigonalisierbar}, falls eine Basis $B = \{v_1,\dots,v_n\}$ von $V$ existiert, sodass die Darstellungsmatrix $A_F^B$ von $F$ bezüglich $B$ eine obere Dreiecksmatrix ist, das heißt für geeignete $\lambda_1,\dots,\lambda_n \in K$ gilt
		\[
			A_F^B = \begin{pmatrix}
			\lambda_1 & * & \cdots & * \\ 
			0 & \lambda_2 & \cdots & * \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda_n
			\end{pmatrix}. 
		\]
		\item Ist $A \in M(n \times n, K)$, so heißt $A$ \Index{trigonalisierbar}, falls ein $S \in \GL(n,K)$ existiert, sodass $S^{-1}AS$ eine obere Dreiecksmatrix ist.
	\end{enumerate}
\end{definition}

\begin{bemerkung}
	\mbox{} \\[-1.4cm]
	\label{bem:9.2}
	\begin{enumerate}[(i)]
		\item Ist $F \in \End_K(V)$ und $A \in M(n \times n,K)$ eine beliebige Darstellungsmatrix von $F$, so gilt:
		\[
			F \text{ ist trigonalisierbar} \quad \Leftrightarrow \quad A \text{ ist trigonalisierbar.}
		\]
		\item Ist $F$ (bzw. $A$) trigonalisierbar, so folgt für das charakteristische Polynom $\chi_F$ (und ähnlich für $\chi_A$), dass
		\[
			\chi_F(T) = \det(TE_n-A_F^B) = \det \begin{pmatrix}
			T-\lambda_1 & * & \cdots & * \\ 
			0 & T-\lambda_2 & \cdots & * \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & T-\lambda_n
			\end{pmatrix} = \prod\limits_{i=1}^{n} (T-\lambda_i).
		\]
		Wir sehen also, dass $\chi_F$ in Linearfaktoren zerfällt und die Diagonalelemente $\lambda_i$ von $A^B_F$ sind gerade die Eigenwerte von $F$.
		\item Aus (ii) folgt:
		Die Matrix $A = \begin{pmatrix}
			0 & 1 \\ -1 & 0
		\end{pmatrix} \in M(2 \times 2,\RR)$ ist nicht trigonalisierbar, da $\chi_A(T) = T^2 +1$ über $\RR$ nicht in Linearfaktoren zerfällt.
		Fassen wir $A$ aber als komplexe Matrix auf, so ist $A$ sogar diagonalisierbar.
		Wir sehen, dass es für diese Fragen ganz wichtig ist, über welchem Körper $K$ wir arbeiten!
	\end{enumerate}
\end{bemerkung}
\newpage
Die Beobachtung in (ii) besitzt auch eine Umkehrung:

\begin{satz}
	\label{satz:9.3}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
	Dann sind äquivalent:
	\begin{enumerate}[(i)]
		\item	$F$ ist diagonalisierbar.
		\item Das charakteristische Polynom $\chi_F$ von $F$ zerfällt in Linearfaktoren.
	\end{enumerate}
\end{satz}

\begin{bemerkung}
	\label{bem:9.4}
	Nach dem Fundamentalsatz der Algebra (\autoref{satz:1.11}) zerfällt jedes komplexe Polynom in Linearfaktoren.
	Aus \autoref{satz:9.3} folgt also insbesondere, dass jedes $F \in \End_{\CC}(V)$ trigonalisierbar ist, wenn $V$ ein endlich dimensionaler $\CC$-Vektorraum ist.
	Allgemeiner gilt:
	Ist $K$ ein \textbf{algebraisch abgeschlossener} Körper (das heißt, dass jedes Polynom über $K$ in Linearfaktoren zerfällt), und ist $V$ ein endlich dimensionaler $K$-Vektorraum, so ist jedes $F \in \End_K(V)$ trigonalisierbar. \index{algebraisch abgeschlossen}
\end{bemerkung}

Die Richtung (i) $\Rightarrow$ (ii) des Satzes folgt aus \autoref{bem:9.2}(ii).
Die andere Richtung werden wir in \autoref{satz:9.6} beweisen, wobei wir auch zeigen werden, dass die gesuche obere Dreiecksmatrix in einer besonderen Form gewählt werden kann.
Wir starten mit:

\begin{definition}[Jordan-Normalform]
	\mbox{} \\[-1.4cm]
	\label{def:9.5}
	\begin{enumerate}[(i)]
		\item Eine Matrix $J \in M(m \times m, K)$ heißt \Index{Jordan-Kasten}, falls ein $\lambda \in K$ existiert mit
		\[
			J = \begin{pmatrix}
			\lambda & 1 & 0 & \cdots & 0 \\ 
			0 & \lambda & 1 & \cdots & 0 \\ 
			\vdots &  & \ddots & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda & 1 \\ 
			0 & \cdots & \cdots & 0 & \lambda
			\end{pmatrix}.
		\]
		Wir sagen dann auch, dass $J$ ein $\lambda$-Jordan-Kasten der Länge $m$ ist.
		\item Eine Matrix $A \in M(n \times n,K)$ heißt \textbf{in Jordan-Normalform} (oder einfach nur \Index{Jordan-Matrix}), falls \index{Jordan-Normalform}
		\[
			A = \begin{pmatrix}
			J_1 & 0 & \cdots & 0 \\ 
			0 & J_2 & \cdots & 0 \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & J_r
			\end{pmatrix}, \text{ sodass }
			J_i = \begin{pmatrix}
			\lambda_i & 1 & 0 & \cdots & 0 \\ 
			0 & \lambda_i & 1 & \cdots & 0 \\ 
			\vdots &  & \ddots & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda_i & 1 \\ 
			0 & \cdots & \cdots & 0 & \lambda_i
			\end{pmatrix} \in M(k_i \times k_i,K)
		\]
		für alle $1 \leq i \leq r$ ein Jordan-Kasten ist.
	\end{enumerate}
\end{definition}

Beachte:
\begin{enumerate}[(i)]
	\item Jede $1 \times 1$-Matrix ist ein Jordan-Kasten der Länge $1$, und damit ist auch jede Diagonalmatrix eine Jordan-Matrix.
	\item Die Eigenwerte $\lambda_i$ der Jordan-Kästen $J_i$ von $A$ müssen nicht paarweise verschieden sein!
	Ein konkretes Beispiel für eine Jordan-Matrix ist gegeben durch
	\[ 
	a = \enb{\begin{BMAT}(e)[4.3pt]{cccccccc}{cccccccc}
	2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 2 & 1 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 2 & 1 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 0 & 3 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 0 & 0 & 3 & 1 \\ 
	0 & 0 & 0 & 0 & 0 & 0 & 0 & 3 
	\addpath{(0,8,|)rrrdddllluuu}
	\addpath{(3,5,|)rrddlluu}
	\addpath{(5,3,|)rdlu}
	\addpath{(6,2,|)rrddlluu}
	\end{BMAT}} = \begin{pmatrix}
		J_1 & 0 & 0 & 0 \\
		0 & J_2 & 0 & 0 \\
		0 & 0 & J_3 & 0 \\
		0 & 0 & 0 & J_4
	\end{pmatrix}
	\]
	mit den Jordan-Kästen
	\[
		J_1 = \begin{pmatrix}
			2 & 1 & 0 \\
			0 & 2 & 1 \\
			0 & 0 & 2
		\end{pmatrix}, J_2 = \begin{pmatrix}
			2 & 1 \\
			0 & 2
		\end{pmatrix}, J_3 = \begin{pmatrix}
		 3
		\end{pmatrix}, J_4 = \begin{pmatrix}
			3 & 1 \\
			0 & 3
		\end{pmatrix}.
	\]
\end{enumerate}

Im Rest dieses Abschnitts werden wir den folgenden Satz beweisen.
Als direkte Folgerung erhalten wir dann auch einen Beweis von \autoref{satz:9.3}.

\begin{satz}[Jordan-Normalform]
	\label{satz:9.6}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$ so, dass das charakteristische Polynom $\chi_F$ von $F$ in Linearfaktoren zerfällt.
	Dann existiert eine Basis $B = \{v_1,\dots,v_n\}$ von $V$, sodass $A_F^B$ eine Jordan-Matrix ist.
	
	Analog: Ist $A \in M(n \times n, K)$ so, dass $\chi_A$ in Linearfaktoren zerfällt, dann existiert ein $S \in \GL(n,K)$, sodass $S^{-1}AS$ eine Jordan-Matrix ist.
\end{satz}

Wie üblich folgt der zweite Teil des Satzes direkt aus dem ersten Teil, wenn wir den Endomorphismus $F_A \colon K^n \rightarrow K^n, x \mapsto Ax$ betrachten und die Elemente der Basis $B$ von $K^n$ wie im ersten Teil des Satzes als Spalten der Matrix $S$ nehmen.

Für den Beweis des Satzes benötigen wir einige Vorbereitungen.

\begin{lemma}[Direkte Summen von Endomorphismen und Blockmatrizen]
	\label{def:9.7}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
	Ist $V_1 \subseteq V$ mit $F(V_1) = V_1$, so können wir einen Endomorphismus $F_1 \in \End_K(V_1)$ durch $F_1(v) := F(v)$ für $v \in V_1$ definieren (also $F_1 = F \big|_{V_1} \colon V_1 \rightarrow V_1$).
	Besitzt $V$ eine direkte Summenzerlegung $V = V_1 \oplus V_2$ mit $F(V_1) \subseteq V_1$ und $F(V_2) \subseteq V_2$, so erhalten wir zwei Endomorphismen $F_1 \in \End_K(V_1)$ und $F_2 \in \End_K(V_2)$, und für jedes $v = v_1 + v_2 \in V$ mit $v_1 \in V_1, v_2 \in V_2$ gilt dann
	\[
		F(v) = F_1(v_1) + F_2(v_2).
	\]
	Wir sagen dann: $F$ ist die \Index{direkte Summe} von $F_1$ und $F_2$ und wir schreiben $F = F_1 \oplus F_2$.
	Sei nun $B_1 = \{v_1,\dots,v_r\}$ eine Basis von $V_1$ und $B_2 = \{v_{r+1},\dots,v_n\}$ eine Basis von $V_2$.
	Dann ist \linebreak $B := \{v_1,\dots,v_r,v_{r+1},\dots,v_n\}$ eine Basis von $V$ und für jedes $v_j$ aus dieser Basis gilt
	\[
	F(v_j) = \begin{cases}
	F_1(v_j) = \sum_{i=1}^{r} a_{ij} v_i, & \text{ falls } j \leq r \\
	F_2(v_j) = \sum_{i=r+1}^{n} a_{ij} v_i, & \text{ falls } r < j.
	\end{cases}
	\]
	Dann hat die Darstellungsmatrix $A := A_F^B$ von $F$ die Gestalt
	\[
	A = \begin{pmatrix}
	A_1 & 0 \\
	0 & A_2
	\end{pmatrix}, \text{ mit } A_1 = A_{F_1}^{B_1} \text{ und } A_2 = A_{F_2}^{B_2}.
	\]
	Sei umgekehrt $F$ ein beliebiger Endomorphismus von $V$, sodass eine Basis $B = \{v_1,\dots, v_r,v_{r+1},\dots,v_n\}$ von $V$ existiert mit $A_F^B = \begin{pmatrix}
	A_1 & 0 \\
	0 & A_2
	\end{pmatrix}$.
	Setzen wir dann $V_1 := \LH\{v_1,\dots,v_r\}$ und $V_2 := \{v_{r+1},\dots,v_n\}$, so folgt $V = V_1 \oplus V_2$ mit $F(V_i) \subseteq V_i$, also $F = F_1 \oplus F_2$ mit $F_i := F\big|_{V_i} \colon V_i \rightarrow V_i$ wie oben.
\end{lemma}

Wir benötigen:

\begin{lemma}
	\label{lemma:9.8}
	\mbox{} \\[-1.4cm]
	\begin{enumerate}[(i)]
		\item Sei $A = \begin{pmatrix}
		A_1 & * \\
		0 & A_2
		\end{pmatrix} \in M(n \times n, K)$ eine Blockmatrix.
		Dann gelten
		\[
			\det(A) = \det(A_1) \cdot \det(A_2) \quad \text{ und } \quad \chi_A = \chi_{A_1} \cdot \chi_{A_2},
		\]
		wobei $\chi_A, \chi_{A_1}$ und $\chi_{A_2}$ die charakteristischen Polynome von $A$, $A_1$ und $A_2$ bezeichnen.
		\item Sei $F = F_1 \oplus F_2$ die direkte Summe zweier Endomorphismen $F_i \in \End_K(V_i), i=1,2$.
		Dann gilt $\det(F) = \det(F_1) \cdot \det(F_2)$ und $\chi_F = \chi_{F_1} \cdot \chi_{F_2}$.
	\end{enumerate}
\end{lemma}

\begin{beweis}
	Sei $A_1 \in M(l \times l,K)$.
	Wir beweisen die Determinantenformel durch Induktion nach $l$.
	Für $l = 1$ folgt die Formel sofort durch Entwicklung der Determinante nach der ersten Spalte.
	Für den Induktionsschritt von $l-1$ nach $l$ sei $A = \begin{pmatrix}
		A_1 & * \\ 0 & A_2
	\end{pmatrix}$ mit $A_1 \in M(l \times l, K), l > 1$.
	Wir nehmen an, dass die Determinantenformel für Blöcke kleinerer Größe bereits bewiesen ist.
	Sei dann $A_i$ die Matrix, die durch Streichen der ersten Spalte und der $i$-ten Zeile von $A$ entsteht, und sei $A_{1,i}$ die Matrix, die durch Streichen der ersten Spalte und der $i$-ten Zeile von $A_1$ entsteht für $1 \leq i \leq l$.
	Dann gilt  $A_i = \begin{pmatrix}
		A_{1,i} & * \\
		0 & A_2
	\end{pmatrix}$ für alle $1 \leq i \leq r$.
	Da alle Einträge der ersten Spalte von $A$ unterhalb der $l$-ten Zeile verschwinden, erhalten wir durch Entwicklung der Determinante von $A$ (bzw. $A_1$) nach der ersten Spalte: \newpage
	\begin{align*}
		\det(A) &\stack{}{=} (-1)^{i+1} a_{i1} \det(A_i) = \sum_{i=1}^{l} (-1)^{i+1} a_{i1} \det \begin{pmatrix}
			A_{1,i} & * \\ 0 & A_2
		\end{pmatrix} \\
		&\stack{\text{I.A.}}{=} \sum_{i=1}^{l} (-1)^{i+1} a_{i1} \det(A_{1,i}) \det(A_2) = \det(A_1) \cdot \det(A_2).
	\end{align*}
	Die Formel für das charakteristische Polynom von $A$ folgt dann durch Anwenden der Determinantenformel auf $TE_n - A = \begin{pmatrix}
		T \cdot E_{n_1} - A_1 & * \\ 0 & T \cdot E_{n_2} - A_2
	\end{pmatrix}$, wobei $A_i \in M(n_i \times n_i,K), i=1,2$.
	Der Beweis von (ii) folgt nun aus (i) und der Tatsache, dass für $F = F_1 \oplus F_2$ eine Darstellungsmatrix der Gestalt $A_F^B = \begin{pmatrix}
		A_{F_1}^{B_1} & 0 \\ 0 & A_{F_2}^{B_2}
	\end{pmatrix}$ existiert. \qedhere
\end{beweis}

Völlig analog zum oben betrachteten Fall $F = F_1 \oplus F_2$ kann man auch direkte Summen von mehr als zwei Endomorphismen betrachten.
Sei dazu $V = V_1 \oplus V_2 \oplus \cdots \oplus V_r$ mit $F(V_i) \subseteq V_i$ für $1 \leq i \leq r$.
Ist $F_i \in \End_K(V_i)$ definiert durch $F_i = F\big|_{V_i}\colon V_i \rightarrow V_i$, so schreiben wir $F = F_1 \oplus F_2 \oplus \cdots \oplus F_r$ und sagen, dass $F$ die direkte Summe von $F_1,\dots,F_r$ ist.
Ist $B_i$ eine Basis von $V_i$ und $B = B_1 \cup \dots \cup B_r$, so folgt wie für den oben behandelten Fall $r=2$:
\[
	A_F^B = \begin{pmatrix}
		A_{F_1}^{B_1} & 0 & \cdots & 0 \\
		0 & \ddots & & \vdots \\
		\vdots & & \ddots & 0 \\
		0 & \cdots & 0 & A_{F_r}^{B_r}
	\end{pmatrix}.
\]
Mit \autoref{lemma:9.8} und einer leichten Induktion erhält man dann
\begin{equation}
	\det(F_1 \oplus \cdots \oplus F_r) = \prod_{i=1}^{r} \det(F_i) \quad \text{und} \quad \chi_F = \prod_{i=1}^{r} \chi_{F_r}. \label{eq:9.1}
\end{equation}

Zurück zur Jordan-Normalform.
Wir wollen zunächst untersuchen, wann $F \in \End_K(V)$ eine Basis $B$ besitzt, sodass $A_F^B$ aus genau einem Jordan-Kasten besteht:

\begin{lemma}
	\label{lemma:9.9}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum, $F \in \End_K(V)$ und sei $B = \{v_1,\dots,v_k\}$ eine Basis von $V$.
	Dann gilt
	\begin{equation}
		A_F^B = \begin{pmatrix}
		\lambda & 1 & 0 & \cdots & 0 \\ 
		0 & \lambda & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & \lambda & 1 \\ 
		0 & \cdots & \cdots & 0 & \lambda
		\end{pmatrix} \quad \Leftrightarrow \quad (F-\lambda \id)(v_i) = \begin{cases}
			v_{i-1}, & \text{ falls } i > 1 \\
			0, & \text{ falls } i = 1
		\end{cases} \label{eq:9.2}
	\end{equation}
\end{lemma}

\begin{beweis}
	Wegen $A_{F - \lambda \id}^B = A_F^B - \lambda E_k$ ist die linke Aussage äquivalent zu $A_{F - \lambda \id}^B = \begin{pmatrix}
		0 & 1 & 0 & \cdots & 0 \\ 
		0 & 0 & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & 0 & 1 \\ 
		0 & \cdots & \cdots & 0 & 0
		\end{pmatrix}$.
	Nach Definition einer Darstellungsmatrix ist dies aber äquivalent zur rechten Aussage.  \qedhere
\end{beweis}

\begin{bemerkung}
	\label{bem:9.10}
	Ist $F$ wie in \autoref{lemma:9.9} und ist $1 \leq l \leq k$, so gilt
	\[
		\Kern(F-\lambda \id)^l = \LH\{v_1,\dots,v_l\}.
	\]
	Insbesondere folgt $\Kern(F- \lambda \id)^k = \LH\{v_1,\dots,v_k\} = V$, also $(F-\lambda \id)^k = 0$.
	
	Allgemeiner gilt: Ist
	\[
		A:= A_F^B = \begin{pmatrix}
		J_1 & 0 & \cdots & 0 \\ 
		0 & J_2 & \cdots & 0 \\ 
		\vdots &  & \ddots & \vdots \\ 
		0 & \cdots & 0 & J_r
		\end{pmatrix}, \text{ sodass }
		J_i = \begin{pmatrix}
		\lambda_i & 1 & 0 & \cdots & 0 \\ 
		0 & \lambda_i & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & \lambda_i & 1 \\ 
		0 & \cdots & \cdots & 0 & \lambda_i
		\end{pmatrix} \in M(k_i \times k_i,K)
	\]
	für jedes $1 \leq i \leq r$ ein Jordan-Kasten zum einzigen Eigenwert $\lambda$ von $F$ ist, so folgt
	\[
		A- \lambda E_n = \begin{pmatrix}
		N_1 & 0 & \cdots & 0 \\ 
		0 & N_2 & \cdots & 0 \\ 
		\vdots &  & \ddots & \vdots \\ 
		0 & \cdots & 0 & N_r
		\end{pmatrix} \text{ mit }
		N_i = \begin{pmatrix}
		0 & 1 & 0 & \cdots & 0 \\ 
		0 & 0 & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & 0 & 1 \\ 
		0 & \cdots & \cdots & 0 & 0
		\end{pmatrix} \in M(k_i \times k_i,K).
	\]
	Damit folgt für $k := \max{k_1,\dots,k_r}$:
	\[
		(A-\lambda E_n)^k = \begin{pmatrix}
		N_1^k & 0 & \cdots & 0 \\ 
		0 & N_2^k & \cdots & 0 \\ 
		\vdots &  & \ddots & \vdots \\ 
		0 & \cdots & 0 & N_r^k
		\end{pmatrix} = 0,
	\]
	also auch $(F-\lambda \id)^k = 0$.
	Endomorphismen mit einer solchen Eigenschaft verdienen einen eigenen Namen!
\end{bemerkung}
\newpage
\begin{definition}[nilpotent]
	\label{def:9.11}
	Sei $V$ ein $K$-Vektorraum.
	Ein $G \in \End_K(V)$ heißt \Index{nilpotent}, falls ein $k \in \NN$ existiert mit $G^k = 0$.

	Analog: Eine Matrix $N \in M(n \times n,K)$ heißt nilpotent, falls ein $k \in \NN$ existiert mit $N^k = 0$.

	Ist dann $k \in \NN$ minimal mit $G^k = 0$ (bzw. $N^k = 0$), so heißt $k$ die \Index{Nilpotenzlänge} von $G$ (bzw. $N$).
\end{definition}

Die Idee im Beweis der Existenz einer Jordan-Normalform für $F \in \End_K(V)$ besteht nun darin, den Raum $V$ in eine direkte Summe
\[
	V = V_{\lambda_1} \oplus V_{\lambda_2} \oplus \cdots \oplus V_{\lambda_m}
\]
zu zerlegen, und entsprechend $F$ in eine direkte Summe $F = F_{\lambda_1} \oplus \cdots \oplus F_{\lambda_m}$ mit $F_{\lambda_i} := F\big|_{V_{\lambda_i}} \colon V_{\lambda_i} \rightarrow V_{\lambda_i}$, wobei $\lambda_1, \dots, \lambda_m$ die paarweise verschiedenen Eigenwerte von $F$ sind und alle $F_i - \lambda_i \id \in \End_K(V_{\lambda_i})$ nilpotent sind.
Gelingt es uns dann, geeignete Basen $B_i$ für $V_{\lambda_i}$ anzugeben, sodass $A_{F_i}^{B_i}$ aus lauter $\lambda_i$-Jordan-Kästen besteht, so wird $B = B_1 \cup \cdots \cup B_m$ zu einer Jordan-Basis von $V$, das heißt $A_F^B$ ist in Jordan-Normalform.
Wir benötigen:

\begin{lemma}
	\label{lemma:9.12}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $G \in \End_K(V)$.
	Für alle $l \in \NN_0$ setze $V_l := \Kern(G^l) \subseteq V$.
	Dann gilt $G(V_l) \subseteq V_{l-1} \subseteq V_l$ für alle $l \in \NN$ und es existiert genau ein $k \in \NN_0$ mit
	\[
		\{0\} = V_0 \subsetneq V_1 \subsetneq V_2 \subsetneq \cdots \subsetneq V_k = V_{k+1}
	\]
	und $V_{l+1} = V_l$ für alle $l \geq k$.
	Insbesondere folgt: $G$ ist genau dann nilpotent, wenn $V_k = V$.
\end{lemma}

\begin{beweis}
	Wegen $G^{l-1}(G(V_l)) = G^l(V_l) = \setzero$ folgt $G(V_l) \subseteq \Kern(G^{l-1}) = V_{l-1}$, und ist $v \in V_{l-1}$, so folgt $G^l(v) = G(G^{l-1}(v)) = G(0) = 0$, also $v \in V_l$.
	Es folgt
	\[
		\setzero = V_0 \subseteq V_1 \subseteq \cdots \subseteq V_l \subseteq V_{l+1} \cdots.
	\]
	Wäre $V_{l+1} \neq V_l$ für alle $l \in \NN$, so wäre $\dim(V) \geq \dim(V_l) \geq l$ für alle $l \in \NN$, also $\dim(V) = \infty$.
	Da aber nach Voraussetzung $\dim(V) < \infty$ gilt, existiert ein kleinstes $k \in \NN_0$ mit $V_{k+1} = V_k$, und dann folgt
	\[
		\setzero = V_0 \subsetneq V_1 \subsetneq V_2 \subsetneq \cdots \subsetneq V_k = V_{k+1}
	\]
	wie im Lemma.
	Für $l \geq k$ gilt dann $V_{l+1} = V_l$, denn wäre $v \in V_{l+1} \setminus V_l$, so wäre $0 = G^{l+1}(v) = G^{k+1}(G^{l-k}(v))$, aber $0 \neq G^l(v) = G^k(G^{l-k}(v))$, also $G^{l-k}(v) \in V_{k+1} \setminus V_k = \emptyset$.
	Dies ist unmöglich. \qedhere
\end{beweis}

\begin{definition}[verallgemeinerter Eigenraum und Eigenvektor]
	\label{def:9.13}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum, $F \in \End_K(V)$ und $\lambda$ ein Eigenwert von $F$.
	Für jedes $l \in \NN_0$ setze $V_{l,\lambda} := \Kern(F-\lambda \id)^l$.
	Nach \autoref{lemma:9.12} existiert ein $k \in \NN$ mit
	\[
		\setzero = V_{0,\lambda} \subsetneq V_{1,\lambda} \subsetneq V_{2.\lambda} \subsetneq \cdots \subsetneq V_{k,\lambda} = V_{k+1,\lambda} =: V_\lambda.
	\]
	\newpage
	Dann heißt $V_\lambda$ der bet{verallgemeinerte Eigenraum} oder \Index{Hauptraum} von $F$ zum Eigenwert $\lambda$. \index{verallgemeinerter Eigenraum}
	Ist $v \in V_\lambda \setminus \setzero$, so heißt $v$ \Index{verallgemeinerter Eigenvektor} von $F$ zum Eigenwert $\lambda$.
	Ist $v \in V_{l,\lambda} \setminus V_{l-1,\lambda}$ für $1 \leq l \leq k$, so heißt $v$ \textbf{verallgemeinerter Eigenvektor der Ordnung} l.
\end{definition}

\begin{bemerkung}
	\label{bem:9.14}
	Wir wollen nun noch einmal von unserem Ziel, der Jordan-Normalform, ausgehen und dabei die Lage des verallgemeinerten Eigenraums $V_\lambda$ genauer betrachten.
	Sei dazu $B$ eine Basis von $V$, sodass $A := A_F^B$ eine Jordan-Matrix ist.
	Durch Vertauschen der Basisvektoren können wir leicht erreichen, dass alle Jordan-Kästen zu einem fest gewählten Eigenwert $\lambda$ von $F$ zuerst auftauchen, also
	\[
		A:= \begin{pmatrix}
			J_{1,\lambda} &        &               &         &        &  \\
			              & \ddots &               &         &        &  \\
			              &        & J_{r,\lambda} &         &        &  \\
			              &        &               & J_{r+1} &        &  \\
			              &        &               &         & \ddots &  \\
			              &        &               &         &        & J_s
		\end{pmatrix},
	\]
	wobei $J_{\lambda,1},\dots,J_{\lambda_r}$ genau die $\lambda$-Kästen von $A$ sind.
	Die Matrix $A - \lambda E_n$ hat dann die Gestalt
	\[
		A - \lambda E_n = \begin{pmatrix}
		N_1 &        &               &         &        &  \\
		& \ddots &               &         &        &  \\
		&        & N_r &         &        &  \\
		&        &               & I_{r+1} &        &  \\
		&        &               &         & \ddots &  \\
		&        &               &         &        & I_s
		\end{pmatrix} \text{ mit } N_i = \begin{pmatrix}
		0 & 1 & 0 & \cdots & 0 \\ 
		0 & 0 & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & 0 & 1 \\ 
		0 & \cdots & \cdots & 0 & 0
		\end{pmatrix} \in M(k_i \times k_i,K)
	\]
	nilpotent der Länge $k_i, 1 \leq i \leq r$, und
	\[
		I_j = \begin{pmatrix}
		\lambda_j - \lambda & 1 & 0 & \cdots & 0 \\ 
		0 & \lambda_j - \lambda & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & \lambda_j - \lambda & 1 \\ 
		0 & \cdots & \cdots & 0 & \lambda_j - \lambda
		\end{pmatrix} \in M(k_j \times k_j,K)
	\]
	invertierbar für alle $r < j < s$, da $\lambda \neq \lambda_j$ und daher $\det(I_j) = (\lambda_j - \lambda)^{k_j} \neq 0$.
	Ist nun $k = \max\{k_1,\dots,k_r\}$, so folgt:
	
	\[
		(A-\lambda E_n)^k = \begin{pmatrix}
		N_1^k &        &               &         &        &  \\
		& \ddots &               &         &        &  \\
		&        & N_r^{k} &         &        &  \\
		&        &               & I_{r+1}^{k} &        &  \\
		&        &               &         & \ddots &  \\
		&        &               &         &        & I_s^{k}
		\end{pmatrix} = \begin{pmatrix}
		0 &        &               &         &        &  \\
		& \ddots &               &         &        &  \\
		&        & 0 &         &        &  \\
		&        &               & I_{r+1}^{k} &        &  \\
		&        &               &         & \ddots &  \\
		&        &               &         &        & I_s^{k}
		\end{pmatrix} = \begin{pmatrix}
			0 & 0 \\ 0 & A_2
		\end{pmatrix}
	\]
	
	mit $A_2 := \begin{pmatrix}
		I^k_{r+1} & & \\
		 & \ddots & \\
		 & & I_s^{k}
	\end{pmatrix}$ invertierbar.
	Zerlegen wir also unsere gegebene Basis in den zu den $\lambda$-Kästen gehörenden Teil $B_1$ und in den restlichen zu den Kästen $J_{r+1},\dots,J_s$ gehörenden Teil $B_2$, so sehen wir, dass $B_1$ den Raum  $V_\lambda = \Kern(F-\lambda \id)^k$ aufspannt, und $B_2$ ist eine Basis des Bildes $\Bild(F-\lambda \id)^k$ von $(F-\lambda \id)^k$.
\end{bemerkung}

Aus diesen Beobachtungen folgt:
Ist der Satz über die Jordan-Normalform wahr, und ist $F \in \End_K(V)$ beliebig, so muss jeder Eigenwert $\lambda$ von $F$ eine Zerlegung $V = V_\lambda \oplus V_2$ induzieren, wobei $V_\lambda = \Kern(F - \lambda \id)^k$ und $V_2 = \Bild(F - \lambda \id)^k$ für ein genügend großes $k \in \NN$.
Diese Beobachtung gibt den entscheidenden Schritt im Beweis von:

\begin{satz}
	\label{satz:9.15}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$ so, dass das charakteristische Polynom $\chi_F$ von $F$ in Linearfaktoren zerfällt.
	Seien $\lambda_1,\dots,\lambda_m$ die paarweise verschiedenen Eigenwerte von $F$ und für jedes $\lambda_i$ sei $V_{\lambda_i}$ der Hauptraum zum Eigenwert $\lambda_i, i = 1, \dots, m$.
	Dann gilt $V = V_{\lambda_1} \oplus V_{\lambda_2} \oplus \cdots \oplus V_{\lambda_m}$ und $F(V_{\lambda_i}) \subseteq V_{\lambda_i}$ für alle $1 \leq i \leq m$.
	Insbesondere folgt $F = F_{\lambda_1} \oplus F_{\lambda_2} \oplus \cdots \oplus F_{\lambda_m}$ mit $F_{\lambda_i} := F\big|_{V_{\lambda_i}} \colon V_{\lambda_i} \rightarrow V_{\lambda_i}$.
\end{satz}

\begin{beweis}
	Wir beweisen den Satz per Induktion nach der Dimension von $V$.
	Ist $\dim(V) = 1$, so ist nichts zu zeigen.
	Sei also nun $\dim(V) = n > 1$ und der Satz sei richtig für kleinere Dimensionen.
	Da $\chi_F$ in Linearfaktoren zerfällt, besitzt $\chi_F$ mindestens eine Nullstelle.
	Also besitzt $F$ mindestens einen Eigenwert $\lambda$.
	Setze $V_1 := V_\lambda$, und wähle $k \in \NN$ wie in \autoref{lemma:9.12} mit $V_\lambda = \Kern(F - \lambda \id)^k$.
	
	Ist $V_\lambda = V$, so ist $\lambda$ der einzige Eigenwert von $F$, denn wäre $\lambda' \neq \lambda$ ein weiterer Eigenwert, so wäre
	\[
		(F-\lambda \id)(v) = F(v) - \lambda v = (\lambda - \lambda')(v)
	\]
	für jeden Eigenvektor $v \neq 0$ von $F$ bezüglich $\lambda'$.
	Aber dann wäre $(F-\lambda \id)^k(v) = (\lambda - \lambda')^kv \neq 0$, da $v \neq 0$ und $\lambda \neq \lambda'$.
	Dies ist aber ein Widerspruch zu $V = V_\lambda = \Kern(F - \lambda \id)^k$.
	Wir erhalten also $F = F_\lambda$ für den einzigen Eigenwert $\lambda$ von $F$, und damit die gewünschte Struktur.
	
	Sei nun $V_\lambda \neq V$.
	Setze $V_1 := V_\lambda$ und $V_2 := \Bild(F - \lambda \id)^k$.
	Wir zeigen:
	\begin{enumerate}[(i)]
		\item $F(V_i) \subseteq V_i$ für $i = 1,2$.
		\item $V = V_1 \oplus V_2$.
	\end{enumerate}
	Für (i) genügt es zu zeigen, dass $(F - \lambda \id)(V_i) \subseteq V_i$ (dann gilt auch $F(V_i) \subseteq (F-\lambda \id)(V_i) + \lambda V_i \subseteq V_i$).
	Für $i = 1$ folgt dies aus $V_1 = \Kern(F - \lambda \id)^k$ und
	\[
		(F-\lambda \id)^k \circ (F-\lambda \id)(V_1) = (F - \lambda \id) \circ (F - \lambda \id)^k(V_1) = (F - \lambda \id)(\setzero) = \setzero.
	\]
	Für $i = 2$ erhalten wir die Rechnung
	\[
		(F-\lambda \id)(V_2) = (F-\lambda \id)((F-\lambda i)^k(V)) = (F - \lambda \id)^k((F - \lambda \id)(V)) \subseteq (F-\lambda \id)^k(V) = V_2.
	\]
	Wir beweisen nun (ii):
	Zunächst folgt aus der Dimensionsformel für die lineare Abbildung $(F-\lambda \id)^k$, dass
	\[
		\dim(V) = \dim(\Kern(F - \lambda \id)^k) + \dim(\Bild(F - \lambda \id)^k) = \dim(V_1) + \dim(V_2).
	\]
	Für den Beweis von (ii) genügt es also zu zeigen, dass $V_1 \cap V_2 = \setzero$.
	Ist aber $v \in V_1 \cap V_2$, so existiert wegen $v \in V_2$ ein $w \in V$ mit $v = (F-\lambda \id)^k(w)$, und da $v \in V_1$, folgt
	\[
		(F- \lambda \id)^k(v) = (F - \lambda \id)^{2k}(w) = 0.
	\]
	Es folgt $w \in V_{2k,\lambda} = \Kern(F - \lambda \id)^{2k}$.
	Nach \autoref{lemma:9.12} und der Wahl von $k$ gilt aber
	\[
		V_\lambda = V_{k,\lambda} = V_{k+1,\lambda} = \cdots = V_{2k,\lambda}.
	\]
	Es folgt $w \in V_{\lambda}$ und $v = (F - \lambda \id)^{k}(w) = 0$.
	
	Aus (i) und (ii) folgt, dass $F = F_1 \oplus F_2$ mit $F_i = F\big|_{V_i} \colon V_i \rightarrow V_i$.
	Nach \autoref{lemma:9.8} gilt $\chi_F = \chi_{F_1} \cdot \chi_{F_2}$, und daher zerfällt mit $\chi_F$ auch $\chi_{F_2}$ in Linearfaktoren.
	Sind $\lambda_2,\dots,\lambda_m$ die paarweise verschiedenen Eigenwerte von $F_2$, so besitzt $F_2$ nach Induktionsvoraussetzung eine Zerlegung $F_2 = F_{\lambda_2} \oplus \cdots \oplus F_{\lambda_m}$, und setzen wir $\lambda_1 := \lambda$, so erhalten wir mit $F_{\lambda_1} = F_1$ die gewünschte Zerlegung $F = F_{\lambda_1} \oplus \cdots \oplus F_{\lambda_m}$. \qedhere
\end{beweis}

\begin{bemerkung}
	\label{bem:9.16}
	Wir sind leider immer noch nicht fertig mit dem Beweis der Existenz der Jordan-Normalform.
	\autoref{satz:9.15} reduziert das Problem aber auf den Fall, dass $F = F_\lambda$ für einen (und dann den einzigen) Eigenwert $\lambda$ von $F$.
	Geligt es uns, für solche Endomorphismen eine Jordan-Basis zu konstruieren, so können wir für jeden Summanden $F_{\lambda_i}$ in der Zerlegung $F = F_{\lambda_1} \oplus \cdots \oplus F_{\lambda_m}$ von \autoref{satz:9.15} eine Basis $B_i$ von $V_{\lambda_i}$ angeben, sodass die zugehörige Darstellungsmatrix $A_i = A^{B_i}_{F_{\lambda_i}}$ eine Jordan-Matrix ist.
	Ist dann $B = B_1 \cup \dots \cup B_l$ die entsprechend zusammengesetzte Basis von $V$, so ist auch
	\[
		A_F^B = \begin{pmatrix}
			A_1 & & \\
			 & \ddots & \\
			 & & A_m
		\end{pmatrix}
	\]
	eine Jordan-Matrix.
	Wir wollen also nun in einem letzten Schritt eine Jordan-Basis für $F_\lambda$ konstruieren! Wir benötigen:
\end{bemerkung}

\begin{lemma}
	\label{lemma:9.17}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $G \in \End_K(V)$ nilpotent.
	Für $l \in \NN_0$ setze $V_l := \Kern(G^l)$.
	Nach \autoref{lemma:9.12} existiert dann ein $k \in \NN$ mit
	\[
		\setzero = V_0 \subsetneq V_1 \subsetneq \cdots \subsetneq V_{k-1} \subsetneq V_k = V.
	\]
	Sei nun $2 \leq l \leq k$ und sei
	\[
		B = \{u_1,\dots,u_r,w_1,\dots,w_s,v_1,\dots,v_t\}
	\]
	eine Basis von $V_l$ so, dass $\{u_1,\dots,u_r\}$ eine Basis für $V_{l-2}$ und $\{u_1,\dots,u_r,w_1,\dots,w_s\}$ eine Basis für $V_{l-1}$ ist.
	Dann gilt $t \leq s$, und wir können die Vektoren $w_1,\dots,w_s \in V_{l-1} \setminus V_{l-2}$ so abändern, dass zusätzlich $G(v_i) = w_i$ für alle $1 \leq i \leq t$ gilt.
\end{lemma}

\begin{beweis}
	Sei $V' = \LH\{v_1,\dots,v_t\}$.
	Dann gilt $V_l = V_{l-1} \oplus V'$, also insbesondere $V' \cap V_{l-1} = \setzero$.
	Wir zeigen zunächst, dass die Vektoren $u_1,\dots,u_r,G(v_1),\dots,G(v_t) \in V_{l-1}$ linear unabhängig sind.
	Sei dazu $0 = \sum_{i=1}^{r} \mu_i u_i + \sum_{j=1}^{t} \nu_j G(v_j)$.
	Setze $u := \sum_{i=1}^{r} \mu_i u_i \in V_{l-2}$ und $v := \sum_{j=1}^{t} \nu_j v_j \in V'$.
	Dann folgt $0 = u+ G(v)$, also $G(v) = -u \in V_{l+2} = \Kern(G^{l-2})$ und damit $v \in \Kern(G^{l-1}) = V_{l-1}$.
	Damit folgt $v \in V' \cap V_{l-1} = \setzero$, also $v = 0$ und dann auch $u = 0$.
	Da $u_1,\dots,u_r$ und $v_1,\dots,v_t$ linear unabhängig sind, erhalten wir $0 = \mu_1 = \cdots = \mu_r = \nu_1 = \dots = \nu_t$.
	Insbesondere folgt $r+t \leq \dim(V_{l-1}) = r+s$, also $t \leq s$.
	
	Setzen wir nun $\wt{w_i} := G(v_i)$ für $1 \leq i \leq t$, so existieren nach dem Basisergänzungssatz weitere Vektoren $\wt{w_{r+1}},\dots,\wt{w_s} \in V_{l-1}$, sodass $\{u_1,\dots,u_r,\wt{w_1},\dots,\wt{w_s}\}$ eine Basis von $V_{l-1}$ ergibt.
	Das System $\{u_1,\dots,u_r,$ \linebreak $\wt{w_1},\dots,\wt{w_s},v_1,\dots,v_t\}$ hat dann alle gewünschten Eigenschaften. \qedhere
\end{beweis}

Wir kommen nun zum Abschluss des Beweises von \autoref{satz:9.6}.
Wir erinnern daran (siehe \autoref{bem:9.16}), dass es genügt, den Fall $V = V_\lambda$ und $F = F_\lambda$ zu betrachten.
Dann ist $F- \lambda \id$ nilpotent!

\begin{satz}
	\label{satz:9.18}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$ mit $V = V_\lambda$ für einen Eigenwert $\lambda$ von $F$.
	Setze $G := F - \lambda \id$ und $V_l := \Kern(G^{l})$ für ein $l \in \NN_0$.
	Sei $k \in \NN$ mit $\setzero = V_0 \subsetneq V_1 \subsetneq \cdots \subsetneq V_k = V$,	und setze $d_l := \dim(V_l) - \dim(V_{l-1})$ für $1 \leq l \leq k$.
	Dann gilt $d_l \leq d_{l-1}$ für alle $2 \leq l \leq k$, und wir finden eine Basis $B$ von $V$ nach dem folgenden Schema:
	
	\[ \begin{array}{ccccccccc}
		v_{1,1} & v_{1,2} & \cdots & \cdots & v_{1,l} & \cdots & \cdots & v_{1,k-1} & v_{1,k} \\ 
		v_{2,1} & v_{2,2} & \cdots & \cdots & v_{2_l} & \cdots & \cdots & v_{2,k-1} & v_{2,k} \\ 
		\vdots & \vdots &  &  & \vdots &  &  & \vdots & \vdots \\ 
		v_{d_k,1} & v_{d_k,2} & \cdots & \cdots & v_{d_k,l} & \cdots & \cdots & v_{d_k,k-1} & v_{d_k,k} \\ 
		\vdots & \vdots &  &  & \vdots &  &  & \vdots &  \\ 
		v_{d_{k-1},1} & v_{d_{k-1},2} & \cdots & \cdots & v_{d_{k-1},l} & \cdots & \cdots & v_{d_{k-1},k-1} &  \\ 
		\vdots & \vdots &  &  & \vdots & \vdots &  &  &  \\ 
		v_{d_l,1} & v_{d_l,2} & \cdots & \cdots & v_{d_l,l} &  &  &  &  \\ 
		\vdots & \vdots & \vdots &  &  &  &  &  &  \\ 
		v_{d_2,1} & v_{d_2,2} &  &  &  &  &  &  &  \\
		\vdots & & & & & & & & \\ 
		v_{d_1,1} &  &  &  &  &  &  &  & 
	\end{array}
	\]
	
	Hierbei gelten:
	\begin{enumerate}[(i)]
		\item Die Vektoren in den ersten $l$ Spalten ergeben zusammen genommen eine Basis von $V_l$.
		Insbesondere bilden alle Bektoren des Schemas eine Basis von $V$.
		\item Ist $1 \leq i \leq d_1$ ein beliebiger Zeilenindex, so gilt $v_{i,l-1} = G(v_i,l)$ für alle $2 \leq l \leq k_i$, wobei $k_i$ der Index derjenigen Spalte ist, in der die $i$-te Zeile endet.
	\end{enumerate}
	Ist dann $B_i$ die $i$-te Zeile des Schemas und setzen wir $B := B_1 \cup \dots \cup B_{d_1}$, so ist $B$ eine Basis von $V$ und $A^B_F$ ist in Jordan-Normalform.
\end{satz}

\begin{beweis}
	Die Beziehung $d_l \leq d_{l-1}$ für $2 \leq l \leq k$ ist eine direkte Konsequenz aus \autoref{lemma:9.17}.
	Zur Konstruktion des Schemas mit den gewünschten Eigenschaften wählen wir zunächst eine Basis $U_1$ von $V_1$, ergänzen diese zu einer Basis $U_2$ von $V_2$ und fahren induktiv fort, bis wir ein Schema
	
	\[
		\begin{array}{ccccccccc}
		u_{1,1} & u_{1,2} & \cdots & \cdots & u_{1,l} & \cdots & \cdots & u_{1,k-1} & u_{1,k} \\ 
		u_{2,1} & u_{2,2} & \cdots & \cdots & u_{2_l} & \cdots & \cdots & u_{2,k-1} & u_{2,k} \\ 
		\vdots & \vdots &  &  & \vdots &  &  & \vdots & \vdots \\ 
		u_{d_k,1} & u_{d_k,2} & \cdots & \cdots & u_{d_k,l} & \cdots & \cdots & u_{d_k,k-1} & u_{d_k,k} \\ 
		\vdots & \vdots &  &  & \vdots &  &  & \vdots &  \\ 
		u_{d_{k-1},1} & u_{d_{k-1},2} & \cdots & \cdots & u_{d_{k-1},l} & \cdots & \cdots & u_{d_{k-1},k-1} &  \\ 
		\vdots & \vdots &  &  & \vdots & \vdots &  &  &  \\ 
		u_{d_l,1} & u_{d_l,2} & \cdots & \cdots & u_{d_l,l} &  &  &  &  \\ 
		\vdots & \vdots & \vdots &  &  &  &  &  &  \\ 
		u_{d_2,1} & u_{d_2,2} &  &  &  &  &  &  &  \\
		\vdots & & & & & & & & \\ 
		u_{d_1,1} &  &  &  &  &  &  &  & 
		\end{array}
	\]
	
	erhalten, indem die ersten $l$ Spalten zusammen jeweils eine Basis von $V_l$ bilden (die Vektoren aus $U_1$ finden wir also in der ersten Spalte, etc.).
	Wir setzen zunächst $v_{i,k} := u_{i,k}$ für $1 \leq i \leq d_k$.
	Durch Anwenden von \autoref{lemma:9.17} auf die vorletzte Spalte können wir dann die Vektoren $u_{1,k-1},\dots,u_{d_{k-1},k-1}$ durch geeignete Vektoren $v_{1,k-1},\dots,v_{d_{k-1},k-1}$ ersetzen, sodass $v_{i,k-1} = G(v_{i,k})$ für $1 \leq i \leq d_{k-1}$ gilt.
	Nach $k$ Schritten erhalten wir dann das gesuchte Schema.
	
	Setzen wir $v_i := v_{i,k_i}$, so folgt aus (ii), dass die $i$-te Zeile $B_i$ des Schemas wie folgt aussieht:
	\[
		B_i = \{G^{k_i-1}(v_i), G^{k_i-2}(v_i), G^{k_i-3}(v_i),\dots,G(v_i),v_i\}.
	\]
	Setzen wir dann $\wt{V_i} := \LH(B_i)$, so folgt $G(\wt{V_i}) \subseteq \wt{V_i}$, und dann auch $F(\wt{V_i}) \subseteq \wt{V_i}$, da $F = G + \lambda \id$.
	\autoref{lemma:9.9} liefert dann, dass $F_i := F\big|_{\wt{V_i}} \colon \wt{V_i} \rightarrow \wt{V_i}$ die Darstellungsmatrix
	\[
		A_{F_i}^{B_i} = J_i = \begin{pmatrix}
		\lambda & 1 & 0 & \cdots & 0 \\ 
		0 & \lambda & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & \lambda & 1 \\ 
		0 & \cdots & \cdots & 0 & \lambda
		\end{pmatrix} \in M(k_i \times k_i,K)
	\]
	besitzt.
	Setzen wir dann $B := B_1 \cup \dots \cup B_{d_1}$, so erhalten wir eine Basis $B$ von $V$ mit
	\[
	A_F^B = \begin{pmatrix}
	J_1 & & \\
	& \ddots & \\
	& & J_{d_1}
	\end{pmatrix}. \qedhere
	\]
\end{beweis}

\begin{bemerkung}
	\label{bem:9.19}
	Die verschiedenen Schritte im Beweis von \autoref{satz:9.6} liefern auch ein Verfahren zur Berechnung der Jordan-Normalform und einer zugehörigen Jordan-Basis.
	Konkret gehen wir wie folgt vor:
	\begin{enumerate}[(i)]
		\item Berechne alle paarweise verschiedenen Eigenwerte $\lambda_1,\dots,\lambda_m$ von $F$.
		\item Sei $\lambda := \lambda_j$ der $j$-te Eigenwert von $F$.
		Bestimme zunächst das minimale $k \in \NN$ mit $\Kern(F-\lambda \id)^{k+1} = \Kern(F-\lambda \id)^k = V_\lambda$.
		Für alle $1 \leq l \leq k$ bestimme eine Familie $C_l = \{u_{1,l},\dots,u_{d_l,l}\}$ von Vektoren in $V$, sodass $C_1 \cup \dots \cup C_l$ eine Basis von $V_{l,\lambda} = \Kern(F-\lambda \id)^l$ ist.
		Hierfür bestimmen wir zunächst eine beliebige Basis $C_1$ von $V_{1,\lambda}$, ergänzen diese durch geeignete Wahl von $C_2$ zu einer Basis von $V_{2,\lambda}$ und fahren entsprechend fort, bis wir $C = C_1 \cup \dots \cup C_k$ bestimmt haben.
		\item Sei $\lambda = \lambda_j$ wie in (ii).
		Setze zunächst $v_{1,k} := u_{1,k}, \dots, v_{d_k,k} := u_{d_k,k}$, und setze dann
		\[
			v_{1,{k-1}} := (F-  \lambda \id)(v_{1,k}), \dots, v_{d_k,k-1} := (F-\lambda \id)(v_{d_k},k).
		\]
		Wähle dann beliebige Vektoren $v_{d_k+1,k-1}, \dots, v_{d_{k-1},k-1}$ aus $C_{k-1}$ so, dass die Vektoren $v_{1,k-1},\dots,$ \linebreak $v_{d_{k-1},k-1}$ linear abhängig sind.
		Haben wir dann nach $l-1$ Schritten die Vektoren $v_{1,l},\dots,v_{d_l,l}$ konstruiert, so setzen wir wieder
		
		\[
			v_{1,l-1} := (F-\lambda \id)(v_{1,l}), \dots, v_{d_l,l-1} := (F-\lambda\id)(v_{d_l},l)
		\]
		
		und wählen weitere Vektoren $v_{d_l+1,l-1}, \dots, v_{d_{l-1},l-1} \in C_{l-1}$ mit $v_{1,l-1},\dots,v_{d_{l-1},l-1}$ linear unabhängig.
		
		Auf diese Weise erhalten wir ein Schema von Vektoren $v_{i,l}$ wie in \autoref{satz:9.18}, das alle im Satz erwähnten Anforderungen erfüllt.
		Wie im Satz beschrieben erhalten wir dann eine Jordan-Basis $B_\lambda$ von $V_\lambda$ für $F_\lambda = F \big|_{V_\lambda}$.
		Genauer: Ist $B_i$ die $i$-te Zeile des Schemas, so setzen wir $B_\lambda := B_1 \cup \dots \cup B_{d_1}$.
		Zu jeder Zeile $B_i$ erhalten wir dann einen $\lambda$-Jordan-Kasten der Länge $k_i$, wenn $k_i$ die Länge der Zeile $B_i$ bezeichnet.
		\item Ist zu jedem $\lambda_j$ wie in (iii) die Basis $B_{\lambda_j}$ von $V_{\lambda_j}$ konstruiert, so ist $B:= B_{\lambda_1} \cup \dots \cup B_{\lambda_m}$ eine Jordan-Basis für $F$.
		Die zugehörige Darstellungsmatrix hat dann die Blockstruktur
		\[
			A_F^B = \begin{pmatrix}
			A_1 & & \\
			& \ddots & \\
			& & A_m
			\end{pmatrix},
		\]
		wobei $A_j$ die in (iii) konstruierte Jordan-Matrix von $F_{\lambda_j}$ ist.
		Beachte: $A_j$ enthält alle Jordan-Kösten zum Eigenwert $\lambda_j$!
	\end{enumerate}
\end{bemerkung}

Beachte: Ist $A \in M(n \times n,K)$, $F \colon K^n \rightarrow K^n, v \mapsto Av$ der zugehörige Endomorphismus und $B = \{c_1,\dots,c_n\}$ eine Jordan-Basis für $F$, so ist $S := (c_1,\dots,c_n)$ eine invertierbare Matrix, sodass $A_F^B = S^{-1}AS$ die zu $B$ gehörende Jordan-Normalform ist.

\begin{beispiel}
	\label{bsp:9.20}
	Sei $F\colon \RR^5 \rightarrow \RR^5, v \mapsto Av$ mit
	\[
		A := \begin{pmatrix}
			1 & 0 & 2 & 3 & 4 \\
			0 & 1 & 0 & -2 & -3 \\
			0 & 0 & 1 & 0 & 2 \\
			0 & 0 & 0 & 1 & -1 \\
			0 & 0 & 0 & 0 & 1
		\end{pmatrix}.
	\]
	Man sieht sofort, dass $\chi_F(T) = \det(TE_5-A) = (T-1)^5$.
	Also ist $1$ der einzige Eigenwert von $F$.
	Nachrechnen ergibt
	\[
		B - E_5 = \begin{pmatrix}
		0 & 0 & 2 & 3 & 4 \\
		0 & 0 & 0 & -2 & -3 \\
		0 & 0 & 0 & 0 & 2 \\
		0 & 0 & 0 & 0 & -1 \\
		0 & 0 & 0 & 0 & 0
		\end{pmatrix}, \quad (B-E_5)^2 = \begin{pmatrix}
		0 & 0 & 0 & 0 & 1 \\
		0 & 0 & 0 & 0 & 2 \\
		0 & 0 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 & 0
		\end{pmatrix}, \quad (B-E_5)^3 = 0.
	\]
	Damit erhalten wir
	\[
		V_1 := \Kern(B-E_5) = \LH\{e_1,e_2\}, \quad V_2 := \Kern(B-E_5)^2 = \LH\{e_1,e_2,e_3,e_3\}, \quad V_3 := \Kern(B-E_5)^3 = \RR^5
	\]
	und
	\[
		d_1 = \dim(V_1) = 2,  \quad d_2 = \dim(V_2) - \dim(V_1) = 2, \quad d_3 = \dim(V_3) - \dim(V_2) = 1.
	\]
	Hieraus folgt, dass die Jordan-Normalform $J$ von $F$ zwei Jordan-Kösten zum Eigenwert $1$ besitzt, und zwar einen der Länge $3$ und einen der Länge $2$.
	Zur Konstruktion einer Jordan-Basis für $F$ setze
	\[
		v_{1,3} := e_5, \quad v_{1,2} = (B-E_5)e_5 = (4,-3,2,-1,0)^T, \quad v_{1,1} = (B-E_5)^2 e_5 = (1,2,0,0,0)^T.
	\]
	Ferner setze $v_{2,2} = e_4$ und $v_{2,1} = (B-E_5)e_4 = (3,-2,0,0,0)^T$.
	Dann ist
	\[
		\begin{array}{ccc}
			v_{1,1} & v_{1,2} & v_{1,3} \\
			v_{2,1} & v_{2,2}
		\end{array}
	\]
	ein Schema wie in \autoref{satz:9.18} und
	\[
		B = \{v_{1,1},v_{1,2},v_{1,3},v_{2,1},v_{2,2}\} = \penb{
			\begin{pmatrix} 1 \\ 2 \\ 0 \\ 0 \\ 0 \end{pmatrix},
			\begin{pmatrix} 4 \\ -3 \\ 2 \\ -1 \\ 0 \end{pmatrix},
			\begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 1 \end{pmatrix},
			\begin{pmatrix} 3 \\ -2 \\ 0 \\ 0 \\ 0 \end{pmatrix},
			\begin{pmatrix} 0 \\ 0 \\ 0 \\ 1 \\ 0 \end{pmatrix}
			}
	\]
	ist eine Jordan-Basis für $F$ mit zugehöriger Jordan-Normalform
	\[
		J := A^B_F = \enb{\begin{BMAT}(e)[4.3pt]{ccccc}{ccccc}
			1 & 1 & 0 & 0 & 0 \\
			0 & 1 & 1 & 0 & 0 \\
			0 & 0 & 1 & 0 & 0 \\
			0 & 0 & 0 & 1 & 1 \\
			0 & 0 & 0 & 0 & 1
			\addpath{(0,2,|)uuurrrdddlll}
			\addpath{(3,0,|)uurrddll}
			\end{BMAT}}.
	\]
	Setzen wir $S := \begin{pmatrix}
		1 & 4 & 0 & 3 & 0 \\
		2 & -3 & 0 & -2 & 0 \\
		0 & 2 & 0 & 0 & 0 \\
		0 & -1 & 0 & 0 & 1 \\
		0 & 0 & 1 & 0 & 0
	\end{pmatrix}$, so folgt $J = S^{-1}AS$.
\end{beispiel}

\subsubsection*{Eine reelle Version der Jordan-Normalform}
Wie wir gesehen haben, besitzt ein Endomorphismus $F \in \End(V)$ eines endlich dimensionalen $K$-Vektorraums genau dann eine Jordan-Normalform, wenn das charakteristische Polynom $\chi_F$ in Linearfaktoren zerfällt.
Ist $K = \CC$, so ist dies wegen des Fundamentalsatzes der Algebra immer der Fall.
Dies ist nicht mehr richtig, wenn $K = \RR$.
Wir wollen nun, ähnlich wie in Abschnitt \ref{sec:2.7} für normale Endomorphismen, eine reelle Version der Jordan-Normalform beschreiben, die für jeden Endomorphismus auf einem endlich dimensionalen reellen Vektorraum anwendbar ist.
Wir wollen hier aber nur die wichtigsten Ideen und nicht alle Einzelheiten des Beweises beschreiben.

Sei also $V$ ein $\RR$-Vektorraum mit $\dim(V) = n < \infty$ und sei $F \in \End_{\RR}(V)$.
Zunächst betrachten wir alle paarweise verschiedenen reellen Eigenwerte $\lambda_1,\dots,\lambda_l$ von $F$.
Wie zuvor bilden wir dann die Haupträume $V_{\lambda_1},\dots,V_{\lambda_l}$ für diese Eigenwerte, und erhalten mit einer leichten Abwandlung von \autoref{satz:9.15} eine Zerlegung
\[
	V = V_{\lambda_1} \oplus \cdots \oplus V_{\lambda_m} \oplus V^c
\]
mit $F(V_{\lambda_i} \subseteq V_{\lambda_i}$ für alle $1 \leq i \leq m$ und $F(V^c) \subseteq V^c$.
Damit erhalten wir dann auch eine entsprechende Zerlegung
\[
	F = F_{\lambda_1} \oplus \cdots \oplus F_{\lambda_m} \oplus F^C
\]
von $F$.
Für den Anteil $F^r := F_{\lambda_1} \oplus \cdots \oplus F_{\lambda_m}$ können wir dann wie gehabt eine Basis $B^r$ von $V^r := V_{\lambda_1} \oplus \cdots \oplus V_{\lambda_m}$ berechnen, sodass
\[
	A_{F^r}^{B^r} = \begin{pmatrix}
		J_1 &        &  \\
		    & \ddots &  \\
		    &        & J_s
	\end{pmatrix}
\]
eine reelle Jordan-Matrix ist.

Wir wollen nun eine Basis $B^c$ von $V^c$ bestimmen, sodass $A_{F^c}^{B^c}$ eine möglichst schöne Blockgestalt hat.
Nach Konstruktion hat $F^c$ keine reellen Eigenwerte.
Sei $V_{\CC}^c = V^c + iV^c$ die Komplexifizierung von $V^c$ und sei $F_{\CC}^c \colon V_{\CC}^c \rightarrow V_{\CC}^c, F_{\CC}^c(v+iw) = F^c(v) + iF^c(w)$ die Komplexifizierung von $F^c$ (vergleiche Abschnitt \ref{sec:2.7}).
Dann rechnet man nach:
Ist $\mu = \alpha + i \beta$ ein nicht-reeller Eigenwert von $F_{\CC}^c$ und ist $V_\mu \subseteq V_{\CC}^c$ der Hauptraum zum Eigenwert $\mu$, so gilt für den Hauptraum $V_{\ol{\mu}}$ zum Eigenwert $\ol{\mu}$:
\[
	V_{\ol{\mu}} = \ol{V_\mu} = \{ \ol{u} : u \in V_{\mu}\},
\]
wobei für $u = v + iw \in V_{\CC}^c$ der konjugierte Vektor $\ol{u}$ definiert ist durch $\ol{u} = v-iw$.
Zerlegen wir nun $V_{\CC}^c$ in die Haupträume der Eigenwerte von $F$ wie in \autoref{satz:9.15}, so erhalten wir eine Zerlegung
\[
	V_{\CC}^c = V_{\mu_1} \oplus V_{\ol{\mu_1}} \oplus \cdots \oplus V_{\mu_m} \oplus V_{\ol{\mu_m}}.
\]
Für jedes komplexe Paar $\mu_j, \ol{\mu_j}$ von Eigenwerte von $F^c$ wählen wir nun zunächst eine Basis $B_j$ von $V_{\mu_j}$, sodass die Darstellungsmatrix des Summanden $F_{\mu_j}^c = F^c \big|_{V_{\mu_j}} \colon V_{\mu_j} \rightarrow V_{\mu_j}$ bezüglich $B_j$ in $\mu_j$-Jordan-Kästen zerfällt.
Ist dann $\ol{B_j} = \{\ol{u} : u \in B_j\}$, so zerfällt auch die Darstellungsmatrix von $F^c_{\ol{\mu_j}} = F^c \big|_{V_{\ol{\mu_j}}} \colon V_{\ol{\mu_j}} \rightarrow V_{\ol{\mu_j}}$ bezüglich $\ol{B_j}$ in $\ol{\mu_j}$-Jordan-Kästen, und die Anzahl und Größe der $\mu_j$-Jordan-Kästen in $A_{F_{\mu_j}^c}^{B_j}$ entspricht der Anzahl und Größe der $\ol{\mu_j}$-Jordan-Kästen in $A_{F_{\ol{\mu_j}}^c}^{\ol{B_j}}$.
Genauer: Ist $\{u_1,\dots,u_k\} \subseteq B_j$ der Anteil von $B_j$, der zu einem $\mu_j$-Jordan-Kasten

\[
	J = \begin{pmatrix}
		\mu_j & 1      &        &  \\
		      & \ddots & \ddots &  \\
		      &        & \ddots & 1     \\
		      &        &        & \mu_j
	\end{pmatrix} \in M(k \times k,\CC)
\]

in $A_{F_{\mu_j}^c}^{B_j}$ gehört, so ist $\{\ol{u_1},\dots,\ol{u_k}\} \subseteq \ol{B_j}$ der Anteil von $\ol{B_j}$, der zum entsprechenden $\ol{\mu_j}$-Jordan-Kasten

\[
	J = \begin{pmatrix}
		\ol{\mu_j} & 1      &        &  \\
		           & \ddots & \ddots &  \\
		           &        & \ddots & 1          \\
		           &        &        & \ol{\mu_j}
	\end{pmatrix} \in M(k \times k,\CC)
\]

in $A_{F_{\ol{\mu_j}}^c}^{\ol{B_j}}$ gehört.
Es folgt aus den obigen Überlegungen, dass 
\[
	\wt{B}_j = \{ v,w : v+iw \in B_j\}
\]
eine Basis von $V_{\mu_j} \oplus V_{\ol{\mu_j}}$ ist.
Ist dann wie oben $\{u_1,\dots,u_k\}$ der Anteil, der zu einem $\mu_j$-Jordan-Kasten von $A_{F_{\mu_j}^c}^{B_j}$ gehört, so erhalten wir für den entsprechenden Anteil $\{v_1,w_1,v_2,w_2,\dots,v_k,w_k\}$ von $\wt{B}_j$ mit $\mu_j = \alpha_j + i \beta_j$:
\begin{align*}
	F^c(v_1) + iF^c(w_1) &= F_{\CC}^c(v_1+iw_1) = F_{\CC}^c(u_1) = \mu_j u_1 = (\alpha_j + i\beta_j)(v_1+iw_1) \\
	&= \alpha_jv_1 - \beta_j w_1 + i(\beta_j v_1 + \alpha_j v_2),
\end{align*}
woraus durch Vergleich von Realteil und Imaginärteil folgt, dass
\[
	F^c(v_1) = \alpha_j v_1 - \beta_j w_1 \qquad \text{und} \qquad F^c(w_1) = \beta_j v_1 + \alpha_j v_2.
\]
Für $2 \leq l \leq k$ erhalten wir
\begin{align*}
	F^c(v_l) + iF^c(w_l) &= F_{\CC}^c(u_l) = u_{l-1} + \mu_j u_l \\
	&= v_{l-1} + \alpha_j v_l - \beta_j w_l + i(w_{l-1} + \beta_j v_l + \alpha_j l v_2),
\end{align*}
woraus dann
\[
	F^c(v_l) = v_{l-1} + \alpha_jv_l - \beta_jw_l \qquad \text{und} \qquad F^c(w_l) = w_{l-1} + \beta_j v_l + \alpha_j lv_2
\]
folgt.
Wenn wir diese Gleichungen in die Definition der Darstellungsmatrix einsetzen, erhalten wir, dass der von $\{v_1,w_1,\dots,v_k,w_k\} \subseteq V^c$ aufgespannte Teilraum von $F^c$-invariant ist, und dies liefert die Blockmatrix

\begin{equation}
	\wt{J} = \enb{\begin{BMAT}(b)[3pt]{cccccccccc}{cccccccc}
		\alpha_j & \beta_j  & 1        &          &        &        &          &          &   &  \\
		-\beta_j & \alpha_j &          & 1        &        &        &          &          &   &  \\
				 &          & \alpha_j & \beta_j  & 1      &        &          &          &   &  \\
				 &          & -\beta_j & \alpha_j &        & 1      &          &          &   &  \\
				 &          &          & \ddots   & \ddots & \ddots & \ddots   &          &   &  \\
				 &          &          &          & \ddots & \ddots & \ddots   & \ddots   &   &  \\
				 &          &          &          &        &        & \alpha_j & \beta_j  & 1 &  \\
				 &          &          &          &        &        & -\beta_j & \alpha_j &   & 1
		\addpath{(0,6,|)uurrddll}
		\addpath{(2,4,|)uurrddll}
		\addpath{(6,0,|)uurrddll}
		\end{BMAT}}.	\label{eq:block_9.3}	
\end{equation}

Wenn wir dies für alle $\mu_j$-Jordan-Kästen und für alle komplexen Paare $\mu_j, \ol{\mu_j}$ von Eigenwerten von $F_{\CC}^c$ durchführen, so erhalten wir eine Basis $B^c$ von $V^c$, sodass die Darstellungsmatrix $A_{F^c}^{B^c}$ eine Blockmatrix mit Blöcken wir in \eqref{eq:block_9.3} ist.
Zusammen mit der Basis von $V^r$, die wir am Anfang gewählt hatten, erhalten wir eine Basis $B$ von $V$, sodass

\[
	A_F^B = \begin{pmatrix}
		J_1 &        &  \\
		    & \ddots &  \\
		    &        & J_r
	\end{pmatrix},
\]

wobei die Blöcke $J_i$ entweder $\lambda$-Jordan-Kästen zu rellen Eigenwerten $\lambda$ von $F$ sind, oder Blöcke der Form \eqref{eq:block_9.3} sind, die zu konjugiert-komplexen Eigenwertpaaren von $F_{\CC}$ gehören.

\begin{beispiel}
	\label{bsp:9.21}
	Wir betrachten den Endomorphismus $F_A \colon \RR^5 \rightarrow \RR^5$ zur Matrix
	
	\[
		A := \enb{\begin{BMAT}(b)[4.3pt]{ccccc}{ccccc}
			1 & 0 & 1  & 0 & 0  \\
			0 & 1 & -2 & 2 & 1  \\
			0 & 2 & 1  & 1 & 1  \\
			0 & 0 & 0  & 1 & -4 \\
			0 & 0 & 0  & 1 & 1
			\addpath{(0,4,|)urdl}
			\addpath{(1,2,|)uurrddll}
			\addpath{(3,0,|)uurrddll}
		\end{BMAT}} \in M(5 \times 5,\RR).
	\]
	
	Diese Matrix ist von der Form $A = \begin{pmatrix}
		A_1 & *   & *   \\
		0   & A_2 & *   \\
		0   & 0   & A_3
	\end{pmatrix}$ mit
	
	\[
		A_1 = \begin{pmatrix}
			1
		\end{pmatrix}, \quad
		A_2 = \begin{pmatrix}
			1 & -2 \\
			2 & 1
		\end{pmatrix}, \quad
		A_3 = \begin{pmatrix}
			1 & -4 \\
			1 & 1
		\end{pmatrix}.
	\]
	
	Daher erhalten wir für das charakteristische Polynom mit Blatt 2, Aufgabe 2:
	
	\[
		\chi_A(T) = \chi_{A_1}(T) \cdot \chi_{A_2}(T) \cdot \chi_{A_3}(T) = (T-1)\enb{(T-1)^2+4} \enb{(T-1)^2+4}.
	\]
	
	Damit hat $F_A$ den Eigenwert $\lambda = 1$ als einzigen reellen Eigenwert, und es existiert ein Paar komplexer Eigenwerte $\mu = 1 + 2i, \ol{\mu} = 1-2i$ mit algebraischer Vielfachheit $2$.
	Es gilt $\Kern(A-E_5) = \RR \cdot (1,0,0,0,0)^T$.
	Für die komplexen Eigenwerte berechnen wir $\Kern(A-\mu E_5)$ und $\Kern(A - \mu E_5)^2$ in $\CC^5$.
	Wir erhalten
	
	\[
		\Kern(A- \mu E_5) = \Kern \begin{pmatrix}
			-2i & 0   & 1   & 0   & 0   \\
			0   & -2i & -2  & 2   & 1   \\
			0   & 2   & -2i & 1   & 1   \\
			0   & 0   & 0   & -2i & -4  \\
			0   & 0   & 0   & 1   & -2i
		\end{pmatrix} = \CC \cdot \begin{pmatrix}
			-i \\ 2i \\ 2 \\ 0 \\ 0
		\end{pmatrix}
	\]
	
	und
	
	\[
		\Kern(A - \mu E_5)^2 = \CC \cdot \begin{pmatrix}
			1 \\ -2 \\ 2i \\ 0 \\ 0
		\end{pmatrix} + \CC \cdot \begin{pmatrix}
			5+i \\ 6-6i \\ 0 \\ 16i \\ 8
		\end{pmatrix}.
	\]
	
	Setzen wir dann $u_2 = (1,-2,2i,0,0)^T$ und $u_3 = (5+i,6-6i,0,16i,8)^T$, so ist $\{u_2\}$ eine Basis von $\Kern(A- \mu E_5)$ und $\{u_2,u_3\}$ eine Basis von $\Kern(A-\mu E_5)^2$.
	Da die algebraische Vielfachheit der Nullstellen $\mu = 1+ 2i$ gleich $2$ ist, muss der Hauptraum zum Eigenwert $\mu$ die Dimension $2$ haben.
	Hieraus folgt schon automatisch, dass $\Kern(A-\mu E_5)^3 = \Kern(A - \mu E_5)^2$ gilt.
	Einsetzen liefert
	
	\[
		(A-\mu E_5) u_3 = (-5-i) u_2 = \begin{pmatrix}
			-5-i \\ 10 + 2i \\ 2 - 10i \\ 0 \\ 0
		\end{pmatrix}.
	\]
	
	(Da $(A-\mu E_5)u_3 \in \Kern(A-\mu E_5) = \CC \cdot u_2$, genügt es zur Bestimmung des Faktors $-5-i$ den Vektor $u_3$ mit der ersten Zeile von $A - \mu E_5$ zu multiplizieren.)
	
	Wir schreiben nun im Folgenden $u_2 := (-5-i, 10+2i, 2-10i, 0, 0)^T$ und vergessen die alte Definition von $u_2$.
	Damit erhalten wir:
	
	Die Vektoren
	\[
		v_1 = \begin{pmatrix}
			1 \\ 0 \\ 0 \\ 0 \\ 0
		\end{pmatrix}, \quad
		u_2 = \begin{pmatrix}
			-5 -i \\ 10+2i \\ 2-10i \\ 0 \\ 0
		\end{pmatrix}, \quad
		u_3 = \begin{pmatrix}
			5+i \\ 6-6i \\ 0 \\ 16i \\ 8
		\end{pmatrix}, \quad
		\ol{u_2} = \begin{pmatrix}
			-5+i \\ 10-2i \\ 2+ 10i \\ 0 \\ 0
		\end{pmatrix}, \quad
		\ol{u_3} = \begin{pmatrix}
			5-i \\ 6+6i \\ 0 \\ -16i \\ 8
		\end{pmatrix}
	\]
	
	bilden eine Basis von $\CC^5$, sodass die Darstellungsmatrix von $(F_A)_{\CC}$ bezüglich dieser Basis die Jordan-Matrix
	
	\[
		J = \enb{\begin{BMAT}(b)[4.3pt]{ccccc}{ccccc}
			1 & 0    & 1     & 0    & 0  \\
			0 & 1+2i & 1     & 0    & 0  \\
			0 & 0    & 1+2i  & 0    & 0  \\
			0 & 0    & 0     & 1-2i & 1 \\
			0 & 0    & 0     & 0    & 1-2i
			\addpath{(0,4,|)urdl}
			\addpath{(1,2,|)uurrddll}
			\addpath{(3,0,|)uurrddll}
			\end{BMAT}}
	\]
	
	ist.
	Dies ist gleichbedeutend mit $S^{-1}AS = J$ für $S = (v_1,u_2,u_3,\ol{u_2},\ol{u_3}) \in M(5 \times 5,\CC)$.
	
	Für die reelle Jordan-Normalform zerlegen wir $u_2 = v_2 + iw_2$ und $u_3 = v_3 + iw_3$ in Real- und Imaginärteil und erhalten die Basis $B = \{v_1,v_2,w_2,v_3,w_3\}$ von $\RR^5$, sodass $F_A$ bezüglich dieser Basis die Darstellungsmatrix
	
	\[
		J_{RR} = \enb{\begin{BMAT}(b)[4.3pt]{ccccc}{ccccc}
			1 & 0  & 1 & 0  & 0  \\
			0 & 1  & 2 & 1  & 0  \\
			0 & -2 & 1 & 0  & 1  \\
			0 & 0  & 0 & 1  & 2 \\
			0 & 0  & 0 & -2 & 1
			\addpath{(0,4,|)urdl}
			\addpath{(1,2,|)uurrddll}
			\addpath{(3,0,|)uurrddll}
			\end{BMAT}},
	\]
	
	besitzt.
	Es gilt dann $R^{-1} AR = J_{\RR}$ mit
	
	\[
		R = (v_1,v_2,w_2,v_3,w_3) = \begin{pmatrix}
			1 & -5 & -1  & 5 & 1  \\
			0 & 10 & 2   & 5 & 1  \\
			0 & 2  & -10 & 0 & 0  \\
			0 & 0  & 0   & 0 & 16 \\
			0 & 0  & 0   & 8 & 0
		\end{pmatrix} \in M(5 \times 5, \RR).
	\]
\end{beispiel}


\newpage