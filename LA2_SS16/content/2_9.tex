%!TEX root = ../LA2.tex
\section{Die Jordan-Normalform}
\label{sec:2.9}

In diesem Abschnitt wollen wir Endomorphismen untersuchen, die nicht unbedingt diagonalisierbar sind.
Wir werden sehen, dass in vielen Fällen eine etwas schwächere Normalform der Darstellungsmatrix von $F$ möglich ist, die zum Beispiel immer noch ermöglicht, den Endomorphismus $\exp(F)$ für $F \in \End_{\CC}(V)$ bzw. $\exp(A)$ für $A \in M(n \times n, \CC)$ zu berechnen.
Wir werden diese Normalform dann später benutzen, um Differentialgleichungen zu lösen.
Wir starten mit:

\begin{definition}[trigonalisierbar]
	\mbox{} \\[-1.4cm]
	\label{def:9.1}
	\begin{enumerate}[(i)]
		\item Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
		Dann heißt $F$ \Index{trigonalisierbar}, falls eine Basis $B = \{v_1,\dots,v_n\}$ von $V$ existiert, sodass die Darstellungsmatrix $A_F^B$ von $F$ bezüglich $B$ eine obere Dreiecksmatrix ist, das heißt für geeignete $\lambda_1,\dots,\lambda_n \in K$ gilt
		\[
			A_F^B = \begin{pmatrix}
			\lambda_1 & * & \cdots & * \\ 
			0 & \lambda_2 & \cdots & * \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda_n
			\end{pmatrix}. 
		\]
		\item Ist $A \in M(n \times n, K)$, so heißt $A$ \Index{trigonalisierbar}, falls ein $S \in \GL(n,K)$ existiert, sodass $S^{-1}AS$ eine obere Dreiecksmatrix ist.
	\end{enumerate}
\end{definition}

\begin{bemerkung}
	\mbox{} \\[-1.4cm]
	\label{bem:9.2}
	\begin{enumerate}[(i)]
		\item Ist $F \in \End_K(V)$ und $A \in M(n \times n,K)$ eine beliebige Darstellungsmatrix von $F$, so gilt:
		\[
			F \text{ ist trigonalisierbar} \quad \Leftrightarrow \quad A \text{ ist trigonalisierbar.}
		\]
		\item Ist $F$ (bzw. $A$) trigonalisierbar, so folgt für das charakteristische Polynom $\chi_F$ (und ähnlich für $\chi_A$), dass
		\[
			\chi_F(T) = \det(TE_n-A_F^B) = \det \begin{pmatrix}
			T-\lambda_1 & * & \cdots & * \\ 
			0 & T-\lambda_2 & \cdots & * \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & T-\lambda_n
			\end{pmatrix} = \prod\limits_{i=1}^{n} (T-\lambda_i).
		\]
		Wir sehen also, dass $\chi_F$ in Linearfaktoren zerfällt und die Diagonalelemente $\lambda_i$ von $A^B_F$ sind gerade die Eigenwerte von $F$.
		\item Aus (ii) folgt:
		Die Matrix $A = \begin{pmatrix}
			0 & 1 \\ -1 & 0
		\end{pmatrix} \in M(2 \times 2,\RR)$ ist nicht trigonalisierbar, da $\chi_A(T) = T^2 +1$ über $\RR$ nicht in Linearfaktoren zerfällt.
		Fassen wir $A$ aber als komplexe Matrix auf, so ist $A$ sogar diagonalisierbar.
		Wir sehen, dass es für diese Fragen ganz wichtig ist, über welchem Körper $K$ wir arbeiten!
	\end{enumerate}
\end{bemerkung}
\newpage
Die Beobachtung in (ii) besitzt auch eine Umkehrung:

\begin{satz}
	\label{satz:9.3}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
	Dann sind äquivalent:
	\begin{enumerate}[(i)]
		\item	$F$ ist diagonalisierbar.
		\item Das charakteristische Polynom $\chi_F$ von $F$ zerfällt in Linearfaktoren.
	\end{enumerate}
\end{satz}

\begin{bemerkung}
	\label{bem:9.4}
	Nach dem Fundamentalsatz der Algebra (\autoref{satz:1.11}) zerfällt jedes komplexe Polynom in Linearfaktoren.
	Aus \autoref{satz:9.3} folgt also insbesondere, dass jedes $F \in \End_{\CC}(V)$ trigonalisierbar ist, wenn $V$ ein endlich dimensionaler $\CC$-Vektorraum ist.
	Allgemeiner gilt:
	Ist $K$ ein \textbf{algebraisch abgeschlossener} Körper (das heißt, dass jedes Polynom über $K$ in Linearfaktoren zerfällt), und ist $V$ ein endlich dimensionaler $K$-Vektorraum, so ist jedes $F \in \End_K(V)$ trigonalisierbar. \index{algebraisch abgeschlossen}
\end{bemerkung}

Die Richtung (i) $\Rightarrow$ (ii) des Satzes folgt aus \autoref{bem:9.2}(ii).
Die andere Richtung werden wir in \autoref{satz:9.6} beweisen, wobei wir auch zeigen werden, dass die gesuche obere Dreiecksmatrix in einer besonderen Form gewählt werden kann.
Wir starten mit:

\begin{definition}[Jordan-Normalform]
	\mbox{} \\[-1.4cm]
	\label{def:9.5}
	\begin{enumerate}[(i)]
		\item Eine Matrix $J \in M(m \times m, K)$ heißt \Index{Jordan-Kasten}, falls ein $\lambda \in K$ existiert mit
		\[
			J = \begin{pmatrix}
			\lambda & 1 & 0 & \cdots & 0 \\ 
			0 & \lambda & 1 & \cdots & 0 \\ 
			\vdots &  & \ddots & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda & 1 \\ 
			0 & \cdots & \cdots & 0 & \lambda
			\end{pmatrix}.
		\]
		Wir sagen dann auch, dass $J$ ein $\lambda$-Jordan-Kasten der Länge $m$ ist.
		\item Eine Matrix $A \in M(n \times n,K)$ heißt \textbf{in Jordan-Normalform} (oder einfach nur \Index{Jordan-Matrix}), falls \index{Jordan-Normalform}
		\[
			A = \begin{pmatrix}
			J_1 & 0 & \cdots & 0 \\ 
			0 & J_2 & \cdots & 0 \\ 
			\vdots &  & \ddots & \vdots \\ 
			0 & \cdots & 0 & J_r
			\end{pmatrix}, \text{ sodass }
			J_i = \begin{pmatrix}
			\lambda_i & 1 & 0 & \cdots & 0 \\ 
			0 & \lambda_i & 1 & \cdots & 0 \\ 
			\vdots &  & \ddots & \ddots & \vdots \\ 
			0 & \cdots & 0 & \lambda_i & 1 \\ 
			0 & \cdots & \cdots & 0 & \lambda_i
			\end{pmatrix} \in M(k_i \times k_i,K)
		\]
		für alle $1 \leq i \leq r$ ein Jordan-Kasten ist.
	\end{enumerate}
\end{definition}

Beachte:
\begin{enumerate}[(i)]
	\item Jede $1 \times 1$-Matrix ist ein Jordan-Kasten der Länge $1$, und damit ist auch jede Diagonalmatrix eine Jordan-Matrix.
	\item Die Eigenwerte $\lambda_i$ der Jordan-Kästen $J_i$ von $A$ müssen nicht paarweise verschieden sein!
	Ein konkretes Beispiel für eine Jordan-Matrix ist gegeben durch
	\[ 
	a = \enb{\begin{BMAT}(b){cccccccc}{cccccccc}
	2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 2 & 1 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 2 & 1 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 0 & 3 & 0 & 0 \\ 
	0 & 0 & 0 & 0 & 0 & 0 & 3 & 1 \\ 
	0 & 0 & 0 & 0 & 0 & 0 & 0 & 3 
	\addpath{(0,8,|)rrrdddllluuu}
	\addpath{(3,5,|)rrddlluu}
	\addpath{(5,3,|)rdlu}
	\addpath{(6,2,|)rrddlluu}
	\end{BMAT}} = \begin{pmatrix}
		J_1 & 0 & 0 & 0 \\
		0 & J_2 & 0 & 0 \\
		0 & 0 & J_3 & 0 \\
		0 & 0 & 0 & J_4
	\end{pmatrix}
	\]
	mit den Jordan-Kästen
	\[
		J_1 = \begin{pmatrix}
			2 & 1 & 0 \\
			0 & 2 & 1 \\
			0 & 0 & 2
		\end{pmatrix}, J_2 = \begin{pmatrix}
			2 & 1 \\
			0 & 2
		\end{pmatrix}, J_3 = \begin{pmatrix}
		 3
		\end{pmatrix}, J_4 = \begin{pmatrix}
			3 & 1 \\
			0 & 3
		\end{pmatrix}.
	\]
\end{enumerate}

Im Rest dieses Abschnitts werden wir den folgenden Satz beweisen.
Als direkte Folgerung erhalten wir dann auch einen Beweis von \autoref{satz:9.3}.

\begin{satz}[Jordan-Normalform]
	\label{satz:9.6}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$ so, dass das charakteristische Polynom $\chi_F$ von $F$ in Linearfaktoren zerfällt.
	Dann existiert eine Basis $B = \{v_1,\dots,v_n\}$ von $V$, sodass $A_F^B$ eine Jordan-Matrix ist.
	
	Analog: Ist $A \in M(n \times n, K)$ so, dass $\chi_A$ in Linearfaktoren zerfällt, dann existiert ein $S \in \GL(n,K)$, sodass $S^{-1}AS$ eine Jordan-Matrix ist.
\end{satz}

Wie üblich folgt der zweite Teil des Satzes direkt aus dem ersten Teil, wenn wir den Endomorphismus $F_A \colon K^n \rightarrow K^n, x \mapsto Ax$ betrachten und die Elemente der Basis $B$ von $K^n$ wie im ersten Teil des Satzes als Spalten der Matrix $S$ nehmen.

Für den Beweis des Satzes benötigen wir einige Vorbereitungen.

\begin{lemma}[Direkte Summen von Endomorphismen und Blockmatrizen]
	\label{def:9.7}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $F \in \End_K(V)$.
	Ist $V_1 \subseteq V$ mit $F(V_1) = V_1$, so können wir einen Endomorphismus $F_1 \in \End_K(V_1)$ durch $F_1(v) := F(v)$ für $v \in V_1$ definieren (also $F_1 = F \big|_{V_1} \colon V_1 \rightarrow V_1$).
	Besitzt $V$ eine direkte Summenzerlegung $V = V_1 \oplus V_2$ mit $F(V_1) \subseteq V_1$ und $F(V_2) \subseteq V_2$, so erhalten wir zwei Endomorphismen $F_1 \in \End_K(V_1)$ und $F_2 \in \End_K(V_2)$, und für jedes $v = v_1 + v_2 \in V$ mit $v_1 \in V_1, v_2 \in V_2$ gilt dann
	\[
		F(v) = F_1(v_1) + F_2(v_2).
	\]
	Wir sagen dann: $F$ ist die \Index{direkte Summe} von $F_1$ und $F_2$ und wir schreiben $F = F_1 \oplus F_2$.
	Sei nun $B_1 = \{v_1,\dots,v_r\}$ eine Basis von $V_1$ und $B_2 = \{v_{r+1},\dots,v_n\}$ eine Basis von $V_2$.
	Dann ist \linebreak $B := \{v_1,\dots,v_r,v_{r+1},\dots,v_n\}$ eine Basis von $V$ und für jedes $v_j$ aus dieser Basis gilt
	\[
	F(v_j) = \begin{cases}
	F_1(v_j) = \sum_{i=1}^{r} a_{ij} v_i, & \text{ falls } j \leq r \\
	F_2(v_j) = \sum_{i=r+1}^{n} a_{ij} v_i, & \text{ falls } r < j.
	\end{cases}
	\]
	Dann hat die Darstellungsmatrix $A := A_F^B$ von $F$ die Gestalt
	\[
	A = \begin{pmatrix}
	A_1 & 0 \\
	0 & A_2
	\end{pmatrix}, \text{ mit } A_1 = A_{F_1}^{B_1} \text{ und } A_2 = A_{F_2}^{B_2}.
	\]
	Sei umgekehrt $F$ ein beliebiger Endomorphismus von $V$, sodass eine Basis $B = \{v_1,\dots, v_r,v_{r+1},\dots,v_n\}$ von $V$ existiert mit $A_F^B = \begin{pmatrix}
	A_1 & 0 \\
	0 & A_2
	\end{pmatrix}$.
	Setzen wir dann $V_1 := \LH\{v_1,\dots,v_r\}$ und $V_2 := \{v_{r+1},\dots,v_n\}$, so folgt $V = V_1 \oplus V_2$ mit $F(V_i) \subseteq V_i$, also $F = F_1 \oplus F_2$ mit $F_i := F\big|_{V_i} \colon V_i \rightarrow V_i$ wie oben.
\end{lemma}

Wir benötigen:

\begin{lemma}
	\label{lemma:9.8}
	\mbox{} \\[-1.4cm]
	\begin{enumerate}[(i)]
		\item Sei $A = \begin{pmatrix}
		A_1 & * \\
		0 & A_2
		\end{pmatrix} \in M(n \times n, K)$ eine Blockmatrix.
		Dann gelten
		\[
			\det(A) = \det(A_1) \cdot \det(A_2) \quad \text{ und } \quad \chi_A = \chi_{A_1} \cdot \chi_{A_2},
		\]
		wobei $\chi_A, \chi_{A_1}$ und $\chi_{A_2}$ die charakteristischen Polynome von $A$, $A_1$ und $A_2$ bezeichnen.
		\item Sei $F = F_1 \oplus F_2$ die direkte Summe zweier Endomorphismen $F_i \in \End_K(V_i), i=1,2$.
		Dann gilt $\det(F) = \det(F_1) \cdot \det(F_2)$ und $\chi_F = \chi_{F_1} \cdot \chi_{F_2}$.
	\end{enumerate}
\end{lemma}

\begin{beweis}
	Sei $A_1 \in M(l \times l,K)$.
	Wir beweisen die Determinantenformel durch Induktion nach $l$.
	Für $l = 1$ folgt die Formel sofort durch Entwicklung der Determinante nach der ersten Spalte.
	Für den Induktionsschritt von $l-1$ nach $l$ sei $A = \begin{pmatrix}
		A_1 & * \\ 0 & A_2
	\end{pmatrix}$ mit $A_1 \in M(l \times l, K), l > 1$.
	Wir nehmen an, dass die Determinantenformel für Blöcke kleinerer Größe bereits bewiesen ist.
	Sei dann $A_i$ die Matrix, die durch Streichen der ersten Spalte und der $i$-ten Zeile von $A$ entsteht, und sei $A_{1,i}$ die Matrix, die durch Streichen der ersten Spalte und der $i$-ten Zeile von $A_1$ entsteht für $1 \leq i \leq l$.
	Dann gilt  $A_i = \begin{pmatrix}
		A_{1,i} & * \\
		0 & A_2
	\end{pmatrix}$ für alle $1 \leq i \leq r$.
	Da alle Einträge der ersten Spalte von $A$ unterhalb der $l$-ten Zeile verschwinden, erhalten wir durch Entwicklung der Determinante von $A$ (bzw. $A_1$) nach der ersten Spalte:
	\begin{align*}
		\det(A) &\stack{}{=} (-1)^{i+1} a_{i1} \det(A_i) = \sum_{i=1}^{l} (-1)^{i+1} a_{i1} \det \begin{pmatrix}
			A_{1,i} & * \\ 0 & A_2
		\end{pmatrix} \\
		&\stack{\text{I.A.}}{=} \sum_{i=1}^{l} (-1)^{i+1} a_{i1} \det(A_{1,i}) \det(A_2) = \det(A_1) \cdot \det(A_2).
	\end{align*}
	Die Formel für das charakteristische Polynom von $A$ folgt dann durch Anwenden der Determinantenformel auf $TE_n - A = \begin{pmatrix}
		T \cdot E_{n_1} - A_1 & * \\ 0 & T \cdot E_{n_2} - A_2
	\end{pmatrix}$, wobei $A_i \in M(n_i \times n_i,K), i=1,2$.
	Der Beweis von (ii) folgt nun aus (i) und der Tatsache, dass für $F = F_1 \oplus F_2$ eine Darstellungsmatrix der Gestalt $A_F^B = \begin{pmatrix}
		A_{F_1}^{B_1} & 0 \\ 0 & A_{F_2}^{B_2}
	\end{pmatrix}$ existiert. \qedhere
\end{beweis}

Völlig analog zum oben betrachteten Fall $F = F_1 \oplus F_2$ kann man auch direkte Summen von mehr als zwei Endomorphismen betrachten.
Sei dazu $V = V_1 \oplus V_2 \oplus \cdots \oplus V_r$ mit $F(V_i) \subseteq V_i$ für $1 \leq i \leq r$.
Ist $F_i \in \End_K(V_i)$ definiert durch $F_i = F\big|_{V_i}\colon V_i \rightarrow V_i$, so schreiben wir $F = F_1 \oplus F_2 \oplus \cdots \oplus F_r$ und sagen, dass $F$ die direkte Summe von $F_1,\dots,F_r$ ist.
Ist $B_i$ eine Basis von $V_i$ und $B = B_1 \cup \dots \cup B_r$, so folgt wie für den oben behandelten Fall $r=2$:
\[
	A_F^B = \begin{pmatrix}
		A_{F_1}^{B_1} & 0 & \cdots & 0 \\
		0 & \ddots & & \vdots \\
		\vdots & & \ddots & 0 \\
		0 & \cdots & 0 & A_{F_r}^{B_r}
	\end{pmatrix}.
\]
Mit \autoref{lemma:9.8} und einer leichten Induktion erhält man dann
\begin{equation}
	\det(F_1 \oplus \cdots \oplus F_r) = \prod_{i=1}^{r} \det(F_i) \quad \text{und} \quad \chi_F = \prod_{i=1}^{r} \chi_{F_r}. \label{eq:9.1}
\end{equation}

Zurück zur Jordan-Normalform.
Wir wollen zunächst untersuchen, wann $F \in \End_K(V)$ eine Basis $B$ besitzt, sodass $A_F^B$ aus genau einem Jordan-Kasten besteht:

\begin{lemma}
	\label{lemma:9.9}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum, $F \in \End_K(V)$ und sei $B = \{v_1,\dots,v_k\}$ eine Basis von $V$.
	Dann gilt
	\begin{equation}
		A_F^B = \begin{pmatrix}
		\lambda & 1 & 0 & \cdots & 0 \\ 
		0 & \lambda & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & \lambda & 1 \\ 
		0 & \cdots & \cdots & 0 & \lambda
		\end{pmatrix} \quad \Leftrightarrow \quad (F-\lambda \id)(v_i) = \begin{cases}
			v_{i-1}, & \text{ falls } i > 1 \\
			0, & \text{ falls } i = 1
		\end{cases} \label{eq:9.2}
	\end{equation}
\end{lemma}

\begin{beweis}
	Wegen $A_{F - \lambda \id}^B = A_F^B - \lambda E_k$ ist die linke Aussage äquivalent zu $A_{F - \lambda \id}^B = \begin{pmatrix}
		0 & 1 & 0 & \cdots & 0 \\ 
		0 & 0 & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & 0 & 1 \\ 
		0 & \cdots & \cdots & 0 & 0
		\end{pmatrix}$.
	Nach Definition einer Darstellungsmatrix ist dies aber äquivalent zur rechten Aussage.  \qedhere
\end{beweis}

\begin{bemerkung}
	\label{bem:9.10}
	Ist $F$ wie in \autoref{lemma:9.9} und ist $1 \leq l \leq k$, so gilt
	\[
		\Kern(F-\lambda \id)^l = \LH\{v_1,\dots,v_l\}.
	\]
	Insbesondere folgt $\Kern(F- \lambda \id)^k = \LH\{v_1,\dots,v_k\} = V$, also $(F-\lambda \id)^k = 0$.
	
	Allgemeiner gilt: Ist
	\[
		A:= A_F^B = \begin{pmatrix}
		J_1 & 0 & \cdots & 0 \\ 
		0 & J_2 & \cdots & 0 \\ 
		\vdots &  & \ddots & \vdots \\ 
		0 & \cdots & 0 & J_r
		\end{pmatrix}, \text{ sodass }
		J_i = \begin{pmatrix}
		\lambda_i & 1 & 0 & \cdots & 0 \\ 
		0 & \lambda_i & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & \lambda_i & 1 \\ 
		0 & \cdots & \cdots & 0 & \lambda_i
		\end{pmatrix} \in M(k_i \times k_i,K)
	\]
	für jedes $1 \leq i \leq r$ ein Jordan-Kasten zum einzigen Eigenwert $\lambda$ von $F$ ist, so folgt
	\[
		A- \lambda E_n = \begin{pmatrix}
		N_1 & 0 & \cdots & 0 \\ 
		0 & N_2 & \cdots & 0 \\ 
		\vdots &  & \ddots & \vdots \\ 
		0 & \cdots & 0 & N_r
		\end{pmatrix} \text{ mit }
		N_i = \begin{pmatrix}
		0 & 1 & 0 & \cdots & 0 \\ 
		0 & 0 & 1 & \cdots & 0 \\ 
		\vdots &  & \ddots & \ddots & \vdots \\ 
		0 & \cdots & 0 & 0 & 1 \\ 
		0 & \cdots & \cdots & 0 & 0
		\end{pmatrix} \in M(k_i \times k_i,K).
	\]
	Damit folgt für $k := \max{k_1,\dots,k_r}$:
	\[
		(A-\lambda E_n)^k = \begin{pmatrix}
		N_1^k & 0 & \cdots & 0 \\ 
		0 & N_2^k & \cdots & 0 \\ 
		\vdots &  & \ddots & \vdots \\ 
		0 & \cdots & 0 & N_r^k
		\end{pmatrix} = 0,
	\]
	also auch $(F-\lambda \id)^k = 0$.
	Endomorphismen mit einer solchen Eigenschaft verdienen einen eigenen Namen!
\end{bemerkung}

\begin{definition}[nilpotent]
	\label{def:9.11}
	Sei $V$ ein $K$-Vektorraum.
	Ein $G \in \End_K(V)$ heißt \Index{nilpotent}, falls ein $k \in \NN$ existiert mit $G^k = 0$.

	Analog: Eine Matrix $N \in M(n \times n,K)$ heißt nilpotent, falls ein $k \in \NN$ existiert mit $N^k = 0$.

	Ist dann $k \in \NN$ minimal mit $G^k = 0$ (bzw. $N^k = 0$), so heißt $k$ die \Index{Nilpotenzlänge} von $G$ (bzw. $N$).
\end{definition}

Die Idee im Beweis der Existenz einer Jordan-Normalform für $F \in \End_K(V)$ besteht nun darin, den Raum $V$ in eine direkte Summe
\[
	V = V_{\lambda_1} \oplus V_{\lambda_2} \oplus \cdots \oplus V_{\lambda_m}
\]
zu zerlegen, und entsprechend $F$ in eine direkte Summe $F = F_{\lambda_1} \oplus \cdots \oplus F_{\lambda_m}$ mit $F_{\lambda_i} := F\big|_{V_{\lambda_i}} \colon V_{\lambda_i} \rightarrow V_{\lambda_i}$, wobei $\lambda_1, \dots, \lambda_m$ die paarweise verschiedenen Eigenwerte von $F$ sind und alle $F_i - \lambda_i \id \in \End_K(V_{\lambda_i})$ nilpotent sind.
Gelingt es uns dann, geeignete Basen $B_i$ für $V_{\lambda_i}$ anzugeben, sodass $A_{F_i}^{B_i}$ aus lauter $\lambda_i$-Jordan-Kästen besteht, so wird $B = B_1 \cup \cdots \cup B_m$ zu einer Jordan-Basis von $V$, das heißt $A_F^B$ ist in Jordan-Normalform.
Wir benötigen:

\begin{lemma}
	\label{lemma:9.12}
	Sei $V$ ein endlich dimensionaler $K$-Vektorraum und sei $G \in \End_K(V)$.
	Für alle $l \in \NN_0$ setze $V_l := \Kern(G^l) \subseteq V$.
	Dann gilt $G(V_l) \subseteq V_{l-1} \subseteq V_l$ für alle $l \in \NN$ und es existiert genau ein $k \in \NN_0$ mit
	\[
		\{0\} = V_0 \subsetneq V_1 \subsetneq V_2 \subsetneq \cdots \subsetneq V_k = V_{k+1}
	\]
	und $V_{l+1} = V_l$ für alle $l \geq k$.
	Insbesondere folgt: $G$ ist genau dann nilpotent, wenn $V_k = V$.
\end{lemma}

\begin{beweis}
	Wegen $G^{l-1}(G(V_l)) = G^l(V_l) = \setzero$ folgt $G(V_l) \subseteq \Kern(G^{l-1}) = V_{l-1}$, und ist $v \in V_{l-1}$, so folgt $G^l(v) = G(G^{l-1}(v)) = G(0) = 0$, also $v \in V_l$.
	Es folgt
	\[
		\setzero = V_0 \subseteq V_1 \subseteq \cdots \subseteq V_l \subseteq V_{l+1} \cdots.
	\]
	Wäre $V_{l+1} \neq V_l$ für alle $l \in \NN$, so wäre $\dim(V) \geq \dim(V_l) \geq l$ für alle $l \in \NN$, also $\dim(V) = \infty$.
	Da aber nach Voraussetzung $\dim(V) < \infty$ gilt, existiert ein kleinstes $k \in \NN_0$ mit $V_{k+1} = V_k$, und dann folgt
	\[
		\setzero = V_0 \subsetneq V_1 \subsetneq V_2 \subsetneq \cdots \subsetneq V_k = V_{k+1}
	\]
	wie im Lemma.
	Für $l \geq k$ gilt dann $V_{l+1} = V_l$, denn wäre $v \in V_{l+1} \setminus V_l$, so wäre $0 = G^{l+1}(v) = G^{k+1}(G^{l-k}(v))$, aber $0 \neq G^l(v) = G^k(G^{l-k}(v))$, also $G^{l-k}(v) \in V_{k+1} \setminus V_k = \emptyset$.
	Dies ist unmöglich. \qedhere
\end{beweis}
\newpage