%!TEX root = ../LA2.tex
\section{Eine Anwendung der Linearen Algebra: Googles PageRank}
\label{sec:2.13}
Zum Schluss möchten wir eine Anwendung der linearen Algebra im Google-Algorithmus \Index{PageRank} erklären.

\minisec{Problem}
Wie entscheidet der Computer bei einer Google-Suche, welche Seiten wichtiger sind als andere und deshalb oben platziert werden sollten?

Natürlich sollten die Seiten das Suchwort (oder verwandte Begriffe) enthalten -- vielleicht kann man auch unterscheiden, ob der Suchbegriff eine zentrale Bedeutung für die Website hat oder nicht (was für eine Maschine nicht leicht entscheidbar ist).

Googles PageRank-Algorithmus (benannt nach Larry \textsc{Page} und entwickelt von Larry \textsc{Page} und Sergey \textsc{Brin} 1996 an der Stanford University) liefert einen Wert für die Wichtigkeit einer Website, die völlig unabhängig vom Inhalt der Seite ist und nur von der Zahl der Links auf diese Seite abhängt, sowie von der Wichtigkeit der Seiten, die auf die gegebene Seite verweisen.
Das geschieht nach dem folgenden Schema:

\begin{problem}
	\label{prob:13.1}
	Wir stellen uns das Internet als gerichteten Graphen vor, dessen Knoten die Webseiten sind und dessen Pfeile die Links von einer Webseite auf eine andere darstellen.
	\begin{figure}[h]
		\centering
	\begin{tikzpicture}[>=Latex,every node/.style={circle,thick,draw,fill=blue!20}]
		\node (W1) at (1,2) {$W_1$};
		\node (W2) at (3,2) {$W_2$};
		\node (W3) at (0,0) {$W_3$};
		\node (W4) at (2,0) {$W_4$};
		\node (W5) at (4,0) {$W_5$};
		\node (W6) at (5,2) {$W_6$};
		
		\path [->] (W1) edge (W3);
		\path [->] (W2) edge (W1);
		\path [->] (W2) edge (W4);
		\path [->] (W3) edge (W4);
		\path [->] (W4) edge (W1);
		\path [->] (W4) edge [bend left] (W5);
		\path [->] (W5) edge [bend left] (W4);
		\path [->] (W5) edge (W2);
		\path [->] (W5) edge (W6);
	\end{tikzpicture}
	\caption{Ein Beispiel mit sechs Webseiten $W_1,\dots,W_6$.}
	\label{fig:13.1}
	\end{figure}
	
	In einem ersten Modell versehen wir jede Webseite mit einer \enquote{Rangwertigkeit} $x_i$, $1 \leq i \leq n$ mit $x_1,\dots,x_n \geq 0$ und $x_1+ \dots + x_n=1$.
	Die Größe jedes einzelnen Werts $x_i$ soll dabei die folgende Regel erfüllen:
	\begin{equation}
		x_i = \sum_{j=1}^{n} a_{ij} x_j, \label{eq:13.1.R}
	\end{equation}
	wobei $a_{ij} \geq 0$ die Wahrscheinlichkeit für den Wechsel von $W_j$ nach $W_i$ darstellt.
	In einem ersten Modell berechnet sich diese wie folgt:
	\begin{enumerate}[(i)]
		\item Ist $W_j$ eine Seite mit $m_j > 0$ Links auf andere Webseiten, so setzen wir
		\[
			a_{ij} = \begin{cases}
				\frac{1}{m_j}, & \text{falls } W_j \text{ auf } W_i \text{ verlinkt} (W_j \leadsto W_j) \\
				0, & \text{sonst.}
			\end{cases}
		\]
		\item Ist $W_j$ eine Webseite ohne Links nach außen (z.B. ein PDF-Dokument), so setze
		\[
			a_{ij} = \frac{1}{n} \text{ für alle } 1 \leq i \leq n,
		\]
		wobei $n$ die Anzahl der Webseiten ist.
	\end{enumerate}
\end{problem}

\begin{definition}[PageRank-Matrix]
	\label{def:13.2}
	Sei $A = (a_{ij}) \in M(n \times n, \RR)$ wie oben.
	Dann heißt $A$ \Index{PageRank-Matrix}.
\end{definition}

Die Regel \eqref{eq:13.1.R} besagt dann, dass der gesuchte \enquote{Rangvektor} $x = (x_1,\dots,x_n)^T \in \RR^n$ die Bedingungen
\begin{equation}
	\begin{cases}
		x_1,\dots,x_n \geq 0, \\
		\sum_{i=1}^{n} x_i = 1, \\
		Ax = x
	\end{cases} \label{eq:13.2.PR}
\end{equation}
erfüllen soll.
Insbesondere ist $x$ ein Eigenvektor zum Eigenwert $1$ von $A$!

\textbf{Problem:} Besitzt \eqref{eq:13.2.PR} immer eine eindeutige Lösung?

\begin{beispiel}
	\label{bsp:13.3}
	In unserem Beispiel in \autoref{fig:13.1} gilt
	\[
		A = \begin{pmatrix}
			0 & \frac{1}{2} & 0 & \frac{1}{2} & 0           & \frac{1}{6} \\
			0 & 0           & 0 & 0           & \frac{1}{3} & \frac{1}{6} \\
			1 & 0           & 0 & 0           & 0           & \frac{1}{6} \\
			0 & \frac{1}{2} & 1 & 0           & \frac{1}{3} & \frac{1}{6} \\
			0 & 0           & 0 & \frac{1}{2} & 0           & \frac{1}{6} \\
			0 & 0           & 0 & 0           & \frac{1}{3} & \frac{1}{6}
		\end{pmatrix}. 
	\]
	Dann gilt $\Kern(A - E) = \RR \cdot (13,6,14,18,5,6)^T$ und $x = \frac{1}{62} (13,6,14,18,5,6)^T$ die eindeutige Lösung für \eqref{eq:13.2.PR}.
	Damit würden die Webseiten $W_1,\dots,W_6$ in folgender Reihenfolge gelistet werden:
	\[
		W_4, W_3, W_1, W_2, W_6, W_5 \quad \text{oder} \quad W_4, W_3, W_1, W_6, W_2, W_5.
	\]
\end{beispiel}

Wir wollen zunächst überlegen, dass die PageRank-Matrix $A$ immer den Eigenwert $1$ besitzt.
Dazu stellen wir zunächst fest:
	
\begin{lemma}
	\label{lemma:13.4}
	Sei $A = (a_{ij})$ eine PageRank-Matrix.
	Dann gilt für alle $1 \leq j \leq n$:
	
	\[
		\sum_{i=1}^n a_{ij} = 1.
	\]
	
	Eine Matrix $A$ mit $a_{ij} \geq 0$ und $\sum_{i=1}^{n} a_{ij} = 1$ für alle $1 \leq j \leq n$ heißt \Index{spaltenstochastische Matrix}.
\end{lemma}

\begin{beweis}
	Ist $j \in \{1,\dots,n\}$ mit $m_j \neq 0$, so gilt $\sum_{i=1}^{n} a_{ij} = \sum_{W_j \leadsto W_i} \frac{1}{m_j} = \frac{m_j}{m_j} = 1$.
	
	Ist $m_j = 0$, so gilt $a_{ij} = \frac{1}{n}$ für alle $i$, also $\sum_{i=1}^{n} a_{ij} = n \cdot \frac{1}{n} = 1$. \qedhere
\end{beweis}

\begin{lemma}
	\label{lemma:13.5}
	Sei $A = (a_{ij}) \in M(n \times n, \RR)$ eine spaltenstochastische Matrix.
	Dann existiert ein $x \in \RR^n \setminus \setzero$ mit $Ax = x$, das heißt $1$ ist ein Eigenwert von $A$.
\end{lemma}

\begin{beweis}
	Wegen $\det(\lambda E_n - A) = \det(\lambda E_n - A)^T = \det(\lambda E_n - A^T)$ genügt es zu zeigen, dass $1$ ein Eigenwert von $A^T$ ist.
	Ist aber $y = (1,1,\dots,1)^T$, so gilt 
	\[
		(A^Ty)_i = \sum_{j=1}^{n} a_{ij}^T y_j = \sum_{j=1}^{n} a_{ji} = 1.
	\]
	Damit ist $y \neq 0$ ein Eigenvektor zum Eigenwert $1$ für $A^T$. \qedhere
\end{beweis}

Wir haben noch nicht gezeigt, dass alle $x_i \geq 0$ gewählt werden können.
Aber das größere Problem ist die Eindeutigkeit der Lösung:

\begin{beispiel}
	\label{bsp:13.6}
	Betrachte das folgende System von Webseiten:
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}[>=Latex,every node/.style={circle,thick,draw,fill=blue!20}]
			\node (W1) at (0,0) {$W_1$};
			\node (W2) at (2,0) {$W_2$};
			\node (W3) at (4,0) {$W_3$};
			\node (W4) at (6,0) {$W_4$};
			
			\path [->] (W1) edge [bend left] (W2);
			\path [->] (W2) edge [bend left] (W1);
			\path [->] (W3) edge [bend left] (W4);
			\path [->] (W4) edge [bend left] (W3);
		\end{tikzpicture}
	\end{figure}
		
	Die zugehörige PageRank-Matrix ist gegeben durch $A = \begin{pmatrix}
			0 & 1 & 0 & 0 \\
			1 & 0 & 0 & 0 \\
			0 & 0 & 0 & 1 \\
			0 & 0 & 1 & 0
		\end{pmatrix}$.
	Dann ist $\Kern(A-E_4) = \RR \cdot (1,1,0,0)^T + \RR \cdot (0,0,1,1)^T$.
	Es gibt hier unendlich viele verschiedene Lösungen von \eqref{eq:13.2.PR}:
	\[
		\lambda \cdot \begin{pmatrix}
			1 \\ 1 \\ 0 \\ 0
		\end{pmatrix} + \mu \cdot \begin{pmatrix}
			0 \\ 0 \\ 1 \\ 1
		\end{pmatrix} \text{ mit } \lambda, \mu \geq 0, \lambda + \mu = \frac{1}{2}.
	\]
\end{beispiel}

Um das Problem der Eindeutigkeit zu lösen, führen \textsc{Page} und \textsc{Brin} einen Dämpfungsfaktor ein:
Sei $0 < c < 1$ und sei $P_n = \begin{pmatrix}
	1 & \cdots & 1 \\
	\vdots & \ddots & \vdots \\
	1 & \cdots & 1
\end{pmatrix}$ (jeder Eintrag von $P_n$ sei $1$).
Setze
\[
	A_c = cA + \frac{1-c}{n} \cdot P_n.
\]

\begin{definition}[gedämpfte PageRang-Matrix]
	\label{def:13.7}
	Wir nennen $A_c$ die \textbf{gedämpfte PageRank-Matrix} mit Dämpfungsfaktor $c$. \index{PageRank-Matrix!gedämpft}
\end{definition}

Man kann den Faktor $c$ wie folgt motivieren:
Mit Wahrscheinlichkeit $c$ folgt der Nutzer auf Webseite $W_j$ einem der Links (falls vorhanden).
Mit Wahrscheinlichkeit $1-c$ gibt er eine beliebige Webadresse in den Browser ein.
In der Literatur wird häufig der Wert $c = 0.85$ als gute Wahl angegeben!

\begin{lemma}
	\label{lemma:13.8}
	Für die Matrix $A_c =: B = (b_{ij})$ gelten:
	\begin{enumerate}[(i)]
		\item $b_{ij} > 0$ für alle $1 \leq i,j \leq n$.
		\item $\sum_{i=1}^{n} b_{ij} = 1$ für alle $1 \leq j \leq n$.
	\end{enumerate}
	Also ist auch $A_c$ eine spaltenstochastische Matrix.
\end{lemma}

\begin{beweis}
	\mbox{} \\[-.9cm]
	\begin{enumerate}[(i)]
		\item Nach Konstruktion von $A$ gilt $a_{ij} \geq 0$ für alle $i,j$.
		Dann folgt $b_{ij} = ca_{ij} + \frac{1-c}{n} > 0$ für alle $i,j$.
		\item Es gilt: 
		\[
			\sum_{i=1}^{n} b_{ij} = \sum_{i=1}^{n} \enb{ca_{ij} + \frac{1-c}{n}} = c \cdot \Underbrace{\sum_{i=1}^{n} a_{ij}}{=1} + (1-c) \sum_{i=1}^{n} \frac{1}{n} = c+(1-c) \frac{n}{n} = 1. \qedhere
		\]
	\end{enumerate}
	\qedhere
\end{beweis}

\begin{beispiel}
	\label{bsp:13.9}
	Wir wollen in \autoref{bsp:13.6} den Dämpfungsfaktor $c = 0.85 = \frac{17}{20}$ betrachten.
	Wir erhalten dann die Matrix
	\[
		A_c = \frac{1}{80} \begin{pmatrix}
			3  & 71 & 3  & 3  \\
			71 & 3  & 3  & 3  \\
			3  & 3  & 3  & 71 \\
			3  & 3  & 71 & 3
		\end{pmatrix}. 
	\]
	Nachrechnen ergibt $\Kern(A_c - E_4) = \RR \cdot (1,1,1,1)^T$ und damit ist $x = \enb{\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4}}^T$ die eindeutige Lösung von \eqref{eq:13.2.PR} für $A_c$.
\end{beispiel}

Die Lösung des Problems der Existenz und Eindeutigkeit einer Lösung für \eqref{eq:13.2.PR} für $A_c$ folgt nun aus: