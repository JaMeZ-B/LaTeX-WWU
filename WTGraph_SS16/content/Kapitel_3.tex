%!TEX root = ./WTG.tex

\chapter{Verzweigungsprozesse, Perkolation und Momentenmethode}

\section{Erste Momentenmethode}

Erinnerung an Galton-Watson-Prozesse. Es geht im die Aussterbewahrscheinlichkeit einer \enquote{idealisierten} Population. Dazu seinen $\enb{L^{(n)}_i}_{i,n}$ Zufallsvariablen mit Werten in $\NN_0$, i.i.d., sodass $L^{(n)}_i \not\equiv 1$ $\p$-f.s. 

Es sei $Z^0 = 1$ und für $1 \geq 1$
\begin{align}
	Z^{(n)} = \sum\limits_{i = 1}^{Z^{(n-1)}} L_i^{(n)} && \text{wobei } Z^{(n-1)} = 0, \text{falls } Z{(n)}  = 0
\end{align}
Frage: Wann überlebt $Z^{(n)}$, d.h. wann ist $\prop{Z^{(n)} > 0\text{ für alle }n} > 0$?

\underline{Es gilt:} \\
\begin{satz}
	Es sei 
	\begin{align}
		q = \propE{Z^{(n)} \text{ stirbt aus} } = \propE{Z^{(n)} = 0, \forall n \geq n_0}
	\end{align}
	Dann ist 
	\begin{enumerate}[a]
	
		\item
			\begin{enumerate}
				\item $q = \lim\limits_{n \to \infty} f^{(n)}(0)$, wobei $f^{(n)} = \EW{s^{Z_n}}$
				\item $q$ ist der kleinste Fixpunkt von $f(s) = \EW{s^L}$, $L = \overset{d}{=} L^(n)$
				\item $q = 1 \Leftrightarrow \EW{L} \leq 1$ \\ $q<1$, falls $\EW{L} > 1$
			\end{enumerate}
		\item $\frac{Z^{(n)}}{m^n}$  ist für $m = \EW{L}$ ein Martingal
		\item $\frac{Z^{(n)}}{m^n}$ konvergiert genau dann gegen einen nicht-entarteten Limes, falls $\EW{L \log L^+} < \infty$
	\end{enumerate}
\end{satz}

Wir wollen nun Galotn-Watson-Prozesse mit Perkolation verbinden. Was ist Perkolation? Ein Modell für ein poröses Medium, d.h. $G=(V,E)$ sei ein unedlicher Graph. Bei der Knotenperkolation entfernt man zufällig Knoten aus $V$, bei der Kantenperkolation entfernt man zufällig Kanten. Wir bbetrachten Kantenperkolation und zumeist Bernoulli-Perkolation mit Parameter $p \in (0,1)$. Man entfernt hierbei Kanten unabhängig voneinander mit Wahrscheinlichkeit $1-p$. \\
\underline{Sprache:} Die Kanten, die man behält, heißen \emph{offen}, die anderen \emph{geschlossen}. Sei $w \subseteq G$ das Produkt eines Perkolationsprozesses, dann heißen die Zusammenhangskomponenten von $w$ (offene) \emph{Cluster}.
\begin{definition}
	Sei $x \in V$. Dann bezeichnen wir mit $k(x)$ das offene Cluster mit $x\in V$. $k(x)$ kann auch einelementig sein. 
\end{definition}

\underline{Zentrale Frage:} Wamm gibt es ein $x$, sodass $k(x)$ unendlichen Durchmesser hat? \\
Diese Frage ist im Allgemeinen schwer, wir versuchen Schranken an die $p$ zu geben, bei denen in der $\Ber(p)$-Perkolation Phasenübergänge stattfinden. Für die obere Schranke benötigen wir nur, dass Ereignisse der Form $\set{w \given x \in w}$ oder $\set{w \given e \in w} = \set{w \given X_e(w) = 1}$ für alle $x \in V, e \in E$ messbar sind, wobei wir $x \notin w$ schreiben, falls $X_e = 0\ \forall e$, deren einer Endpunkt $x$ ist.
\begin{definition}
	Für $x,y \in V$ und $e \in E$ schreiben wir
	\begin{align}
		\benb{x \leftrightarrow e} := \set{e^-,e^+ \in k(x)}  := \set{e \in k(x)} && \text{für }e = \set{e^-,e^+} \\
		\benb{x \leftrightarrow y} = \set{k(x) = k(y)} = \set{w \given y \in k(x)} \\
		\benb{x \leftrightarrow \infty} := \set{w \given k(x) \text{ hat einen unendlichen Durchmesser}}
	\end{align}

\end{definition}

\begin{uebung}
	Diese Ereignisse sind messbar.
\end{uebung}
Um die Wahrscheinlichkeit von $\benb{x \leftrightarrow \infty}$ beschränken zu können, benötigen wir eine Version des Cutsets. Sei $\Pi \subseteq E$. Wir sagen, dass $\Pi$ $x$ von $\infty$ trennt, falls das Löschen der Kanten von $\Pi$ aus $E$ dazu führt, dass $k(x)$ endlich ist. Wir geben eine erste Schranke an $\propE{x \leftrightarrow \infty}$.
\begin{satz}
	\label{satz:6-3}
	Für alle Perkolationsprozesse auf einem unendlichen Graphen $G = (V,E)$ gilt
	\begin{align}
		\propE{x \leftrightarrow \infty} \leq \inf \set{\sum\limits_{e \in \Pi} \prop{x \leftrightarrow e} \given \text{$\Pi$ trennt $x$ von $\infty$} }
	\end{align}
\end{satz}
\begin{beweis}
	Sei $\Pi$ so, dass $\Pi$ $x$ von $ \infty$ trennt, dann gilt: $\benb{x \leftrightarrow \infty} \subseteq \bigcup\limits_{e \in \Pi} \benb{x \leftrightarrow e}$. Also
	\begin{align}
		\propE{x \leftrightarrow \infty} \leq \propE{\bigcup\limits_{e \in \Pi}\benb{x \leftrightarrow e}} \leq \sum\limits_{e \in \Pi}\propE{x \leftrightarrow e}
	\end{align}
	Da das für jede Menge $\Pi$ gilt, die $x$ von $\infty$ trennt, gilt es auch für das Infimum über all solche $\Pi$
\end{beweis}
Diese einfache Schranke heißt \emph{erste Momentenmethode} und liefert manchmal erstaunlich gute Ergebnisse.

Wir betrachten nun eine $\Ber(p)$-Kantenperkolation 
\begin{align}
	\propE{\text{w hat einen $\infty$ Cluster}}[][p]
\end{align}
In diesem Fall ist $\propE{\text{w hat einen $\infty$ Cluster}}[][p] \in \set{0,1}$, da $\set{w \text{ hat einen $\infty$ Cluster}}$ nicht von endlich vielen Indikatoren $X_e(w), e \in E$ abhängt, folgt dies aus dem Kolmogorovschen-$0$-$1$-Gesetz. \marginnote{$X_e(w) = \begin{cases}
	0 &,e \in w \\
	1 &,e \notin w
	\end{cases}$} \todo{häßlich}
Es ist intuitiv klar, dass $p \to \propE{\text{w hat einen $\infty$ Cluster}}[][p]$ monoton wachsend ist. Mathematisch folgt das aus einem Kopplungsargument. Dafür seien für jedes $e \in E$ $U(e) \sim \mathcal{U}[0,1]$ i.i.d.. Für ein gegebenes $p$ und eine Realisierung der $\big(U(e) \big)_{e \in E}$ sei nun $X(e)= 1$ für $U(e) \leq p$ und $0$ sonst. $X(e)$ ergibt eine Bernoulli-Kantenperkolation mit Parameter $p$. Ist nun $p' > p$ realisiere zu jeder festen Realisierung der $\big(U(e)\big)$ und
\begin{align}
	X'(e) = \begin{cases}
				1, & U(e) = p' \\
				0, & sonst
			\end{cases}
\end{align}
$\big(X'(e)\big)$ ist eine $\Ber(p')$-Perkolation. Hat nun die Realisierung der $\big(X(e)\big)$ ein $\infty$ Cluster, so auch die der $\big(X'(e)\big)$. Daher können wir 
\begin{align}
	p_c(G) := \sup\set{p \given \propE{w\text{ hat ein $\infty$ Cluster}} = 0 }
\end{align}
als die kritische Perkolationswahrscheinlichkeit definieren.

\begin{uebung}
	Wenn $G$ zusammenhängend ist, dann ist 
	\begin{align}
		p_c(G):= \sup\set{p \given \prop{\abs{k(x)} = \infty } = 0}
	\end{align}
	Im Allgemeinen ist $p_c(G)$ sehr schwierig zu berechnen. Bekannt ist $p_c(\ZZ)$ und $P_c(\ZZ^2) = \frac{1}{2}.$ Für $P_c(\ZZ^3)$ existiert noch nicht einmal eine Vermutung (der Physiker).
\end{uebung}

Daher betrachten wir Perkolation auf Bäumen. Hier kann man versuchen $\propE{0 \leftrightarrow \infty} \leq \inf\limits_{\Pi \text{ trennt }0 \leftrightarrow \infty}\sum\limits_{e \in \Pi} \propE{0 \leftrightarrow e}[p]$ auszurechnen. \todo{häßlich}
Der Vorteil eines Baumes ist, dass $\prop{0 \leftrightarrow e}[T] = p^{\abs{e}}$
Daher: Ist $p < \frac{1}{br(T)}$, wobei 
\begin{align} 
	br(T) = \sup\limits_{\lambda}\benb{\inf\limits_{\Pi} \sum\limits_{e \in \Pi} \lambda^{-\abs{e}} > 0 }. 
\end{align}
Dann folgt
\begin{align}
	\inf\limits_{\Pi} \sum\limits_{e \in \Pi} p^{\abs{e}} = 0,
\end{align}
weil $\frac{1}{p} > br(T) \Rightarrow \inf\limits_{\pi} \sum\limits_{e \in \Pi} (\frac{1}{p})^{-\abs{e}} = 0$. Dann ist also $\prop{0 \leftrightarrow \infty}[][p] = 0$, womit aus \autoref{satz:6-3} 
\begin{align}
	p_c(T) \geq \frac{1}{br(T)} \label{eqn:6-1}
\end{align}

Es gilt in \eqref{eqn:6-1} sogar Gleichheit, dazu benötigen wir allerdings etwas mehr Technik. Besonders übersichtilich ist die Situatuin, wenn $T$ $n$-regulär ist, d.h. jeder Knoten hat $n$ Kinder. Lässt man auf einem $n$-regulären Baum $\Ber(p)$-Kantenperkolation los, so ergibgt sich ein Galton-Watson-Baum mit $B(n,p)$-verteilter Kinderzahl. Also (da $\EW{B(n,p)} = np$) folgt, dass $p_L (T) = \frac{1}{n}$. Sehr ähnlich zeigt man
\begin{satz}[Lyons '90]
	\label{satz:6-4}
	Sei T ein superkritischer Galton-Watson-Baum mit $\EW{L} = m > 1$. Bedingt darauf, dass $T$ unendlich ist, ist $p_L(T) = \frac{1}{m}$ fast sicher. 
\end{satz}
\begin{beweis} Nur Beweisidee: Wenn man GW und Perkolation simultan laufen lässt, so ist dies wieder ein G-W-Prozess mit Wahrscheinlichkeit $pm$. Also überlebt er genau dann, wenn $p > \frac{1}{m}$. Da die endlichen $T$'s kein endliches unendliches Cluster erzeugen können, folgt mit ein paar Berechnungen die Behauptung. 
\end{beweis}

\marginnote{Vorlesungsbeginn 03.05.2016}

%Wir betrachten Perkolation auf unendlichen Graphen $G= (V,E)$, d.h. eine Teilmenge $E'(w) \subseteq E$ wird gemäß eines Zufallsmechanismus entfernt. \\
%\underline{Zentrale Frage:} Gibt es in $(V,E\backslash E')$ ein unendlich großes Cluster?
%
%Wir betrachten meist $Ber(p)$-Perkolation, d.h. man behält Kanten unabhängig voneinander mit Wahrscheinlichkeit $o \Rightarrow \prop{\exists \infty \text{ Cluster}}[][p] \in \set{0,1}$. Da $p \rightarrow \prop{\exists \infty \text{ Cluster}}[][p]$ monoton, existiert
%\begin{align}
%	p_c = \sup\set{p \given \prop{\exists \infty \text{ Cluster}}[][p] = 0}
%\end{align}
%
%Wir haben gezeigt:
%\begin{satz}
%	\begin{align}
%		\propE{x \leftrightarrow \infty} \leq \inf\set{\sum\limits_{e \in \Pi} \propE{x \leftrightarrow e} \given \Pi \text{ trennt $x$ von $\infty$}  }		
%	\end{align}
%	Daraus haben wir gefolgert: Ist $G$ ein Baum, 
%
%\end{satz}

\begin{korollar}
	Sei $T$ die Realisierung eines Galton-Watson-Prozesses. Dann gilt, bedingt auf das Überleben 
	\begin{align}
		br(T) = m, f.s.
	\end{align}
\end{korollar}
\begin{beweis}
	Aus \autoref{satz:6-4} folgt
	\begin{align}
		br(T) \geq \frac{1}{p_c(T)} = m
	\end{align}
	Aus der folgenden Übung ergibt sich $br(T) \leq gr(T) = m$
\end{beweis}
\begin{uebung}
	Man zeige für einen Galton-Watson-Baum $T$ mit $m = \EW{L} > 1$, dass bedingt auf Überleben $gr(T) = m$ ist.
\end{uebung}

\section{Zweite Momentenmethode} \todo{nummerierung}
Die erste Momentenmethode erlaubt eine (ganz einfache) obere Schranke an $\propE{x \leftrightarrow \infty}$ zu geben. Für untere Schranken benötigt man typischerweise Kenntnisse über das Fluktuationsverhalten der mitspielenden Zufallsvariablen.
So etwas erhält man typischerweise aus Chebyshev-Ungleichungen bzw. der 2. Momentenmethode. Wir betrachten hier eine \enquote{gewichtete} 2. Momentenmethode, d.h. für eine Menge $\Pi$, die $x$ von $\infty$ trennt, werden wir $\prop{o \leftrightarrow e}, e\in \Pi$ mit dem anderen Gewocht $\mu(e)$ abschätzen. Wir werden von nun an wieder $x = o$ wählen und $k(o)$ sei das Cluster von $o$. Sei weiter $\Pi$ ein $o \leftrightarrow \infty$-Cutset und $\mu \in M^1(\Pi)$. Wir betrachten
\begin{align}
	X(y) = \sum\limits_{e \in \Pi} \mu(e) \mathds{1}_{\set{e \in k(o)}} \frac{1}{\prop{c \in k(o)}}
\end{align}
Nebenrechnung: $\prop{o \leftrightarrow \infty} = \inf \prop{o \leftrightarrow \Pi \given \Pi \text{ ist ein $o$-$\infty$-Cutset}}$

\begin{bemerkung}
	\begin{align}
		\EW{X(\mu)} = \EW{\sum\limits_{e \in \Pi} \mu(e) \frac{\mathds{1}_{\set{e \in k(o)}}}{\prop{e \in k(o)}}} = \sum\limits_{e \in \Pi} \mu(e) \frac{\prop{e \in k(o)}}{\prop{e \in k(o)}} = 1
	\end{align}
Sei $\set{o \leftrightarrow \Pi} := \set{\omega \given \exists \ e \in \Pi: o \leftrightarrow e}$. Dann ist 
\begin{align}
	\set{\omega \given X(\mu) > 0} \subseteq \set{\omega \given o \leftrightarrow \Pi} \Rightarrow \prop{X(\mu) > 0} \leq \prop{0 \leftrightarrow \Pi}
\end{align}
\end{bemerkung} 
Da man $\prop{o \leftrightarrow \infty}$ über das Infimum von $\prop{o \leftrightarrow \Pi}$ bestimmen kann, ergibt eine untere Schranke an $\prop{X(\mu) > 0}$ auch eine untere Schranke an $\prop{o \leftrightarrow \infty}$. Das funktioniert wie folgt.

\begin{satz}
	\label{satz:6-8}
	Es sei ein allgemeines Perkolationsmodell auf einem Graphen $G$ gegeben. Dann gilt für $\mu \in M^1(\Pi)$ und jedes $o$-$\infty$-Cutset $\Pi$
	\begin{align}
		\propE{o \leftrightarrow \infty} > \frac{1}{\EW{X^2(\mu)}}
	\end{align}
\end{satz}
\begin{beweis}
	Sei $\Pi$ ein Cutset und $\mu \in M^1(\Pi)$. Dann gilt mit Cauchy-Schwarz
	\begin{align}
		1 = \enb{\EW{X(\mu)}}^2 = \EWE{X(\mu) \mathds{1}_{\set{X(\mu) > o}}}^2 &\leq \EW{X^2(\mu)} \prop{X(\mu) > o} \\
							& \EW{X^2(\mu)} \prop{o \leftrightarrow \infty} 
	\end{align}
	Der Trick ist jetzt: 1. Wähle das \enquote{richige} $\mu$. 2. Schätze $\EW{X^2(\mu)}$ ab.
\end{beweis}

Die Schranken aus \autoref{satz:6-8} ist nur dann effektiv, wenn wir $\EW{X^2(\mu)}$ bestimmen können. Offenbar
\begin{align}
	\EW{X^2(\mu)} = \sum\limits_{e_1,e_2 \in \Pi} \mu(e_1) \mu(e_2) \frac{\prop{e_1,e_2 \in k(o)}}{\prop{e_1 \in k(o)} \prop{e \in k(o)}}
\end{align}

\begin{definition}
	\begin{align}
		\mathcal{E}(\mu) := \sum\limits_{e_1,e_2 \in \Pi} \mu(e_1) \mu(e_2) \frac{\prop{e_1,e_2 \in k(o)}}{\prop{e_1 \in k(o)} \prop{e \in k(o)}}
	\end{align}
	heißt \emph{Energie} von $\mu$
\end{definition}

\begin{korollar}
	\label{kor:6-10}
	\begin{align}
		\prop{o \leftrightarrow \infty} \geq \sup\limits_{\Pi\text{ Cutset von } o\leftrightarrow \infty} \Bigg\{\frac{1}{\inf\limits_{\mu \in M^1(\Pi)} \mathcal{E}(\mu)}\Bigg\}
	\end{align}
\end{korollar}
\begin{beweis}
	Wir haben das schon für alle $\Pi$ und $\mu \in M^1(\Pi)$ gesehen.
\end{beweis}
Damit wir weiterkommen benötigen wir nun Abschätzungen an $\mathcal{E}(\mu)$. Im Allgemeinen kann das schwierig sein, für $G=T$ (Bäume) ist es hingegen einfacher. Sei nun $G =  T = (V,E)$ ein Baum und darauf unabhängige $\Ber(p)$-Kantenperkolationen. Wir identifizieren die Kante in einem Vertex $x$ oft mit diesem Vertex und schreiben $e(x)$ für diese Kante. Für $\mu(e(x))$ schreibe auch $\mu(x)$. Sei nun $\Pi$ ein Cutset in einem Baum $T$ und $\mu \in M^1(\Pi)$. Dann gilt:
\begin{align}
	\mathcal{E}(\mu) &= \sum\limits_{e(x),e(y) \in \Pi} \mu(x)\mu(y) \frac{\prop{x,y\in k(o)}}{\prop{x \in k(o)} \prop{y \in k(o)}}  \\ \marginnote{wobei $x \land y$ der jüngste gemeinsame Vorfahre von $x$ und $y$ ist.}
					&= \sum\limits_{e(x),e(y) \in \Pi} \mu(x) \mu(y) \frac{\prop{x \land y \in k(o)} \prop{x \land y \leftrightarrow x} \prop{x \land y \leftrightarrow y} }{\prop{x \land y \in k(o)} \prop{x \land y \leftrightarrow x} \prop{x \land y \in k(o)} \prop{x \land y \leftrightarrow y} } \\
					&=\sum\limits_{e(x),e(y) \in \Pi} \mu(x) \mu(y) \frac{1}{\prop{o \leftrightarrow x \land y}}
\end{align}

\todo{Mehr erklärung?}
Das hat eine gewisse Ähnlichkeit mit der Rechnung für Flüsse.
\begin{lemma}
	Sei $\Theta$ ein Fluss auf einem endlichen Baum $T$ von der Wurzel $o$ in die Blätter $\delta T$. Dann gilt
	\begin{align}
		\mathcal{E}(\Theta) = \sum\limits_{x,y \in \delta T}\Theta(x) \Theta(y) \mathcal{R}(o \leftrightarrow x\land y) \marginnote{$\Theta(x) = \Theta(e(x))$}
	\end{align}
\end{lemma}
\begin{beweis}
	Benutze $\sum\limits_{x \in \delta T: e \leq x} \Theta(x) = \Theta(e), \forall e$. Dann
	\begin{align}
		\sum\limits_{x,y \in \delta T} \Theta(x) \Theta(y) \mathcal{R}(o \leftrightarrow x \land y) &= \sum\limits_{x,y \in \delta T} \Theta(x) \Theta(y) \sum\limits_{e \leq x\land y} r(e) \\
			&= \sum\limits_{e} r(e) \sum\limits_{\substack{x,y \in \delta T \\ x,y \geq e}} \Theta(x) \Theta(y)\\
			&= \sum\limits_{e} r(e) \Theta^2(e) = \mathcal{E}(\Theta)
	\end{align}
\end{beweis}
Schön wäre es nun diese Beobachtungen zu verknüpfen: Man wählt für $\Theta$ den durch $\mu$ induzierten Fluss $\Theta(e):= \sum\limits_{e \leq x \overline{\Pi}}\mu(x).$\marginnote{$\overline{\Pi} = \set{x \given x(r) \in \Pi}$} Dann ist $\Theta(e(x)) = \mu(e(x)), \forall x \in \delta T$. Kann man auch noch Leitfähigkeiten wählen, sodass $\prop{o \leftrightarrow x}  = \mathcal{C}(o \leftrightarrow x) (*)$ gilt, so folgt $\mathcal{E}(\mu) = \mathcal{E}(\Theta)$. Das geht leider nicht: $(*)$ ist z.B. für $o = x$ falsch. \\
\underline{2. Versuch:} Können wir Leitfähigkeiten $c$ so bestimmten, dass 
\begin{align}
	\frac{1}{\prop{o \leftrightarrow x}} = 1+\mathcal{R}(o \leftrightarrow x) 
\end{align}
so gilt:
\begin{align}
	\mathcal{E}(\mu) = \mathcal{E}(\Theta) + 1 
\end{align}
was dafür, Schranken an $\mathcal{E}(\mu)$ zu erhalten, ebenso gut ist. Falls $c$ so gewählt ist, dass \autoref{kor:6-10} richtig ist, heißt $c$ an das \emph{Perkolationsproblem angepasst}. 

Sei von nun an $G$ ein Baum. Beobachtung: Jetzt ist \marginnote{Vorlesungsbeginn 02.06.2016}
\begin{align}
	\mathcal{E}(\mu)  = \sum\limits_{e(x),e(y)}\mu(x)\mu(y) \frac{1}{\propE{o \leftrightarrow x \land y}}
\end{align}
Andererseits gilt für Flüsse $\Theta$ auf $G$ von $o$ in $\delta T$ (wenn $G=T$ endlich ist)
\begin{align}
	\mathcal{E}(\Theta) = \sum\limits_{x,y \in \delta T}\Theta(x) \Theta(y) \mathcal{R}(o \leftrightarrow x\land y)
\end{align}
Suche nun Leitfähigkeiten $c$, sodass $\frac{1}{\propE{o \leftrightarrow x}} = \mathcal{R}\enb{o \leftrightarrow x} +1, \forall x$. Dann $\mathcal{E}(\mu) = 1 + \mathcal{E}(\Theta)$ für den durch $\mu$ induzierten Fluss, d.h. man kann statt mit $\mathcal{E}(\mu)$ mit $\mathcal{E}(\Theta)$ arbeiten. 
Wie findet man diese Leitfähigkeiten? Da es zu jedem $x$ in einem Baum genau einen Pfad von $o$ nach $x$ gibt, ist $\mathcal{R}\enb{o \leftrightarrow x}$ nichts anderes als der Widerstand einer Reihenschaltung. Sei nun $e(x) = \enb{\overleftarrow{x},x}$, dann ist 
\begin{align} 
		r(e(x)) &= \mathcal{R} (o \leftrightarrow x) - \mathcal{R}\enb{o \leftrightarrow \overleftarrow{x}} = \mathcal{R} \enb{o \leftrightarrow x} + 1 - \enb{\mathcal{R}(o \leftrightarrow \overleftarrow 
		{x}) +1} \\
		&= \frac{1}{\prop{o \leftrightarrow x}} - \frac{1}{\prop{o \leftrightarrow \overleftarrow{x}}} = \frac{1}{\prop{o \leftrightarrow x}} - \frac{p_x}{\prop{o \leftrightarrow \overleftarrow{x}} p_x } = \frac{1-p_x}{\prop{o \leftrightarrow x}} \marginnote{$p_x = \prop{e(x) = 1}$} \\
		\Rightarrow c(e(x)) = \frac{\prop{o \leftrightarrow x}}{1-p_x}
\end{align}
Insbesondere gilt ür $\Ber(p)$-Perkolation $c(e(x)) = \frac{p^{\abs{x}}}{1-p}$. Das sind gerade die Leitfähigkeiten des $\text{RW}_{\lambda}$-randomwalks auf $T$ mit $\lambda = \frac{1}{p}$. Wir können jetzt zeigen:
\begin{satz}[Lyons '90]
	Für unabhängige Perkolation mit Wahrscheinlichkeit $p$ auf dem Baum gilt
	\begin{align}
		\propE{o \leftrightarrow \infty} \geq \frac{\mathcal{C}(o \leftrightarrow \infty)}{1+ \mathcal{C}\enb{o \leftrightarrow \infty}}
	\end{align}	
\end{satz}
\begin{beweis}
	Erinnerung: es gilt $\propE{o \leftrightarrow \infty} \geq \inf\limits_{\substack{\Pi \text{ ist } o\leftrightarrow \infty \\ \text{Cutset}}} \set{\frac{1}{\inf\limits_{\mu \in M^1(\Pi)} \mathcal{E}(\mu)}}$.
	Wir schätzen das Infimum rechts ab. Gegeben sei ein bezüglich \enquote{$\subseteq$} minimales Cutset. Sei $\mu$ eine Wahrscheinlichkeit auf $\Pi$ mit minimaler Energie. Sei $\Theta$ der induzierte Fluss von $o$ nach $\overline{\Pi} = \set{x \given \enb{\overleftarrow{x},x} \in \Pi}$. Das ist auch ein Fluss minimaler Energie. 
	Seien nun die Leitfähigkeiten an das Perkolationsproblem angepasst. Dann gilt
	\begin{align}
		\mathcal{E}(\mu) = 1 + \mathcal{E}(\Theta) = 1+ \mathcal{R}\enb{o \leftrightarrow \overline{\Pi}}
	\end{align}
	d.h. 
	\begin{align}
		\propE{o \leftrightarrow \infty} \geq \inf\limits_{\Pi} \frac{1}{\mathcal{E(\mu)}} = \inf\limits_{\Pi} \frac{1}{1+\mathcal{R}\enb{o \leftrightarrow \overline{\Pi}}} = \frac{1}{1+ \mathcal{o \leftrightarrow \infty}} = \frac{1}{1 + \frac{1}{e \enb{o \leftrightarrow \infty}}} = \frac{e\enb{o \leftrightarrow \infty}}{1 + e(o \leftrightarrow \infty)}
	\end{align}
\end{beweis}
	
\section{Rekurrenz und Transienz von Perkolationsclustern}
$p_c(G)$ ist für viele Graphen insbesondere aber für $G = \ZZ^d$ schwer zu berechnen. Vielleicht ist die folgende Frage einfacher. Ist \underline{das} $\infty$-Perkolationscluster von $\ZZ^d$ rekurrent oder transient?. Die Frage ist für $d=1,2$ trivial, da das Cluster ein Teilgraph eines rekurrenten Graphen ist, folgt die Behauptung aus dem Prinzip von Raleigh (\ref{satz:Rayleigh}).

Sei $d \geq 3$. Wir brauchen ein technisches Hilfsmittel, das aber allgemein interessant ist. 

\begin{satz}[Pakey-Zygmund-Ungleichung]
	Sei $X$ eine Zuvallsvariable mit $\EW{X} = 1$ und existiere $\EW{X^2}$. Dann gilt für alle t < 1
	\begin{align}
		\prop{X > t} \geq \frac{\enb{1-t}^2}{\EW{X^2}}
	\end{align}
\end{satz}
\begin{beweis}
	Das Bemerkenswerte an dieser Ungleichung ist, dass sie eine nicht-triviale untere Schranke an die Wahrscheinlichkeit legt. Sei $A = \set{w \given X(w) \geq t}$. Dann gilt 
	\begin{align}
		\EW{X^2} \prop{A} = \EW{X^2} \EW{\mathds{1}^2_A} \geq \enb{\EW(X\mathds{1}_A)}^2 = \enb{1 - \EW{X\mathds{1}_{A^c}}}^2 \geq \enb{1 - t}^2, \marginnote{$1 = \EW{X} = \EW{X\mathds{1}_A} + \EW{X\mathds{1}_{A^c}}$}
	\end{align}
	wobei die erste Ungleichung aus Cauchy-Schwarz folgt und die Zweite gilt da, die linke Seit für $w\in A,$ gleich $1^2$ und für $w\in A^c$ größer gleich $(1-t)^2$ ist.
\end{beweis}
		
Um diese Ungleichung anzuwenden müssen wir Wahrscheinlichkeiten definieren. Wir wollen hierfür Wahrscheinlichkeiten auf den Pfaden von einem Konten $a$ nach $t$ (oder $\infty$) in einen Graphen $G = (V,E)$ definieren. Anders als vorher sind dies keine Wahrscheinlichkeiten auf Cutsets. Die Kernidee wird sein, dass solche Pfade Flüssen identifizieren und die Frage ist, ob wir die Wahrscheinlichkeiten auf der Pfadmenge so wählen können, dass die assoziierten Flüsse endliche Energie haben (Weil wir gesehen haben, dass die Existenz von Flüssen endlicher Energie die Transienz des Graphen impliziert). Wir beginnen in einer endlichen Situation. 

Es sei $\Gamma= \set{\gamma \text{ ist ein Pfad von $a$ nach $t$} }, a,z \in \infty$-Perkolationscluster.

Sei $\mu$ ein Wahrscheinlichkeitsmaß auf $\Gamma$ und sei $\p$ das Maß der $\Ber(p)$-kantenperkolation auf $\ZZ^d$. Gegeben eine Realisierung $\omega$ der Perkolation, definiere ein positives Maß $Y_{\mu}(\omega)$ auf $\Gamma$ vermöge
\begin{gather}
	Y_{\mu}(\omega)[\gamma] = \begin{cases}
								\frac{\mu(\gamma)}{\propE{\gamma \text{ offen}}}, & \text{falls } \gamma \subseteq \omega \\
								0, & \text{sonst}
						\end{cases}		
\end{gather} 
Diesem positiven Maß kann man nun einen Fluss $\Theta_{\mu} (\omega)$ zuordnen, wobei 
\begin{align}
	\Theta_{\mu}(\omega) = Y_{\mu}(\omega)[e \in \gamma] - Y_{\mu}(\omega)[-e \in \gamma]
\end{align}
Das $Y$ ist zwar ein positives Maß, aber nicht notwendig ein Wahrscheinlichkeitsmaß, d.h. $\Theta_{\mu}(\omega)$ ist nicht notwendig ein Einheitsfluss. Man berechnet 
\begin{align}
	S (\Theta_{\mu}(\omega)) = X_{\mu}(\omega) \sum\limits_{\gamma \subseteq \omega} \frac{\mu(\gamma)}{\propE{\gamma \subseteq \omega}} 
\end{align}
\underline{N.B.} S ist eine Zufallsvariable. Es gilt $\EW{X_{\mu}}(\omega) = \sum \mu(\gamma) = 1$ und
\begin{align}
\EW{X^2_{\mu}}(\omega) &= \sum\limits_{\gamma_1,\gamma_2}\mu(\gamma_1) \mu(\gamma_2) \frac{\prop{\gamma_1 \cup \gamma_2 \subseteq \omega}}{\prop{\gamma_1 \text{ offen}} \prop{\gamma_2 \text{ offen}}} \\
	&= \sum\limits_{\gamma_1,\gamma_2} \mu(\gamma_1)\mu(\gamma_2) \frac{p^{\abs{\gamma_1 \cap \gamma_2}} p^{\abs{\gamma_2 \backslash \enb{\gamma_1 \cap \gamma_2}}} p^{\abs{\gamma_1 \backslash \gamma_1 \cap \gamma_2}} } {p^{\abs{\gamma_1 \cap \gamma_2}} p^{\abs{\gamma_2 \backslash \enb{\gamma_1 \cap \gamma_2}}} p^{\abs{\gamma \cap \gamma 2}}} {p^{\abs{\gamma_1 \backslash \gamma_1 \cap \gamma_2}}} \\ 
	&= \sum\limits_{\gamma_1, \gamma_2} \mu(\gamma_1)\mu(\gamma_2) p^{-\abs{\gamma_1 \cap \gamma_2}}
\end{align}
was eine erstaunliche Ähnlichkeit zu den Formeln oben hat. \\
Ähnlich
\begin{align}
	\mathcal{E}\enb{\Theta_{\mu}(\omega)} = \sum\limits_{e} \Theta^2_{\mu} (\omega)[e] \underbrace{r(e)}_{=1} \leq \sum\limits_{e}\enb{ \sum\limits_{\gamma \ni e} \frac{\mu(\gamma) \mathds{1}_{[\gamma \subseteq \omega]}}{\propE{\gamma \subseteq \omega}}}^2
\end{align}		
und damit 
\begin{align}
	\mathcal{E}(\Theta_{\mu}(w)) &= \sum\limits_{e} \sum\limits_{\gamma_1,\gamma_2 \ni e} \mu(\gamma_1)^\mu(\gamma_2) p^{-\abs{\gamma_1 \cap \gamma_2}} \\
		&= \sum\limits_{\gamma_1,\gamma_2}\abs{\gamma_1 \cap \gamma_2} \mu(\gamma_1) \mu(\gamma_2) p^{-\abs{\gamma_1 \cap \gamma_2}} \\
		&= \sum\limits_{n \geq 1} np^{-n} (\mu \times \mu) \benb{\abs{\gamma_1 \cap \gamma_2} = n}
\end{align}
Strategie: finde $\mu$, sodass das endlich ist. 
		
\marginnote{Vorlesungsbeginn 06.06.2016}
Eine kurze Rekapitulation: Wir waren dabei zu studieren, ob und wann Perkolationscluster in $\ZZ^d$ rekurrent oder transient sind. Ohne Beschränkung ist $d \geq 3$, da für $d=1,2$ die Irrfahrt schon rekurrent ist (Rayleigh). Wir haben auch schon den Satz von Poley-Zigmund gesehen.

Für einen endlichen Graphen $G = (V,E)$ mit $a,z \in V$ sei $\Gamma = \set{\gamma\given \gamma \text{ist Pfad von $a$ nach $z$}}$ und $\mu \in M^1(\Gamma)$. Gegeben eine Realisierung $\omega$ der Perkolation, sei $Y(\omega)$ das folgende positive Maß auf $\Gamma$:
\begin{align} 
	Y_{\mu} (\omega) \land \benb{\gamma} = \begin{cases}
	\frac{\mu(\gamma)}{\prop{\gamma \subseteq \omega}} & , \gamma \subseteq \omega \\
	0 & , \text{ sonst}
	\end{cases}
\end{align}
$Y_{\mu}(\omega)$ induziert einen Fluss $\Theta_{\mu}(\omega)$ der Stärke 
\begin{align}
	X_{\mu}(\omega) = \sum\limits_{\gamma \subseteq \omega} \frac{\mu(\gamma)}{\prop{\gamma \text{ offen}}} && \EW{X_{\mu}} = 1 && \EW{X_{\mu}^2} = \sum\limits_{\gamma, \gamma'} \mu(\gamma) \mu(\gamma') p^{-\abs{\gamma \cap \gamma'}} 
\end{align}
Für die Energie des Flusses haben wir gefunden, dass 
\begin{align*}
	\EW{\mathcal{E}(\Theta_{\mu})} \leq \sum\limits_{n \geq 1} n p^{-h} \enb{\mu \times \mu}(\abs{\gamma \cap \gamma'} = n) \tag{$*$} \label{eq:6-3}
\end{align*}
Wir haben noch die Freiheit $\mu \in M^1(\Gamma)$ zu wählen und wir versuchen $\mu$ so zu wählen, dass die rechte Seite von \eqref{eq:6-3} ist. Hierfür hilft es, wenn $(\mu \times \mu)(\abs{\gamma \cap \gamma'} = n)$ schnell (in $n$) abfällt. Wir sagen, dass $\mu$ einen \emph{Exponential-Intersection-Teil} mit Parameter $\xi < 1$ hat, falls
\begin{align}
	\enb{\mu \times \mu}\enb{\abs{\gamma \cap \gamma'} = n} \leq C \cdot \xi^n \tag{EIT($\xi$)}\label{eq:EIT}
\end{align} 
Wir zeigen 
\begin{enumerate}
	\item \ref{eq:EIT} $\Rightarrow$ Transienz von Perkolationsclustern für hinreichend großes $p$.
	\item In $\ZZ^d, d \geq 4$ gibt es Maße mit \ref{eq:EIT}
\end{enumerate}

\begin{satz}
	Falls $\mu \in M^1(\Gamma)$ mit \ref{eq:EIT}$, \xi < 1 $ existiert, dann ist der $\Ber(p)$-Perkolationscluster für $1 > p > \xi$ $\p$-f.s transient.
\end{satz}
\begin{beweis}
	Die Wahrscheinlichkeit, dass ein $\Ber(p)$-Perkolationscluster transient ist, ist entweder 0 oder 1, denn wenn $\omega$ transient, dann hängt es nur von den Variablen außerhalb jedes Würfels ab. Die Kernidee ist nun, den effektiven Widerstand von $o$ nach $\infty$ abzuschätzen. Dazu verkleben wir wieder alle Punkte außerhalb von $\benb{-r,r}^d$ zu einem Punkt $z_r$ und erhalten einen endlichen Graphen. In diesem schätzen wir $\mathcal{R}(o \leftrightarrow z_r)$ ab. Es gilt für einen beliebigen Einheitsfluss $\tau$
	\begin{align}
		\mathcal{R}\enb{o \leftrightarrow z_r} \leq \mathcal{E}(\tau)
	\end{align}
	und somit
	\begin{align}
		\mathcal{R}(o \leftrightarrow z_r;\infty) \leq \mathcal{E}(\overline{\Theta}_{\mu,r}) = \frac{\mathcal{E}(\Theta_r)}{X^2_r} && \text{mit \quad } \overline{\Theta}_{\mu,r} =: \frac{\Theta_{\mu,r}}{X_{\mu,r}}=:\frac{\Theta_r}{X_r}
	\end{align}
	Dies wollen wir abschätzen.	Berechnet man 
	\begin{align}
		\EW{X^2_r} = \sum\limits_{\gamma,\gamma'}\mu(\gamma)\mu(\gamma')p^{-\abs{\gamma \cap \gamma'}} = \sum\limits_{n \geq 1} p^{-n} \enb{\mu \times \mu}\enb{\abs{\gamma \cap \gamma'} = n} \leq C \sum\limits_{n \geq 1} \enb{\frac{\xi}{p}}^n = C \frac{\xi}{p - \xi}
	\end{align}
	Erinnerung:
	\begin{align}
		\EW{X_r} = 1 \Rightarrow \prop{X_r > \frac{1}{2}} \geq \frac{p - \xi}{4C\xi} =: \delta > 0
	\end{align}
	Andererseits:
	\begin{align}
		\EWE{ \mathcal{E}(\Theta_r)} \leq C \sum\limits_{n \geq 1} n \enb{\frac{\xi}{p}}^n = \frac{Cp\xi}{\enb{p-\xi}^2}=: N
	\end{align}
	\begin{align}
		\propE{\mathcal{E}(\Theta_r) \geq \beta } \leq \frac{n}{\beta} \text{ nach Markov}. 
	\end{align}
	Somit 
	\begin{align}
		\propE{\mathcal{R}(o \leftrightarrow z_r,w) < 4\beta} \geq \propE{X_r > \frac{1}{2}, \mathcal{E}(\Theta_r) \leq \beta} = \propE{X_r > \frac{1}{2}} - \propE{\mathcal{E}(\Theta_e)> \beta} \geq \delta-\frac{n}{p} = \frac{\delta}{2} 
	\end{align}
	für $\frac{n}{\beta} = \frac{\delta}{2}$. Hängt nicht von $r$ ab.

	\begin{align}
		r &\mapsto \mathcal{R}(o \leftrightarrow z_r,w) \text{ ist wachsend} \\
		r &\mapsto \propE{\mathcal{R}(o \leftrightarrow z_r,w) \leq \beta} \text{ ist somit fallend.}
	\end{align}
	Allerdings sind die Wahrscheinlichkeiten uniform nach unten beschränkt. Also ist die Wahrscheinlichkeit $\propE{\mathcal{R}(o\leftrightarrow \infty,w) \leq 4\beta} = \propE{\bigcap_n \mathcal{R}(o \leftrightarrow z_r,w) \leq 4\beta} \geq \frac{\delta}{2}>0$ (Stetigkeit von Wahrscheinlichkeiten) Also ist $\mathcal{R}(o \leftrightarrow \infty,w)$ mit positiver Wahrscheinlichkeit endlich und d.h. mit positiver Wahrscheinlichkeit ist $C(o)$ transient, also gibt es mit Wahrscheinlichkeit 1 ein transientes, unendliches Cluster. 
\end{beweis}

Nun zur Transienz von Perkolationsclustern in $\ZZ^d, d\geq 4$.
\begin{satz}
	Für $d \geq 4$ gibt es auf $\ZZ^d$ Maße $\mu$ auf $\Gamma = \set{\gamma \given \gamma \text{ ist } 0 \leftrightarrow \infty \text{-Pfad}}$ mit EIT$(\xi)$ und $\xi<1$.
\end{satz}
\begin{beweis}
	ObdA sei $d=4$, denn auf $\ZZ^4$ . Sei $\mu$ das Maß auf $0 \leftrightarrow \infty$-Pfade, sodass diese Zuwächse der Form $(1,0,0,0), (0,1,0,0),(0,0,1,0),(0,0,0,1)$ mit Wahrscheinlichkeit $\frac{1}{4}$ haben. Wir wollen zeigen, dass dieses Maß EIT hat. Wir betrachten also $(\mu \times \mu)(\abs{\gamma \cap \gamma'} = n)$. Nun ist $\abs{\gamma \cap \gamma'} \leq \abs{\set{n \given \gamma(n) = \gamma'(n)}}$, da man keine Kante rückwärts durchläuft und sich immer von der $0$ wegbewegt, müssen $\gamma$ und $\gamma'$ die gleiche Kante auch zur gleichen Zeit benutzen. Damit müssen sie aber auch zur gleichen Zeit im Ursprungspunkt der Kante sein. 
	
	Studiere also die Tails von $\abs{\set{n \given: \gamma(n) = \gamma'(n)}}$. Dazu betrachte $\gamma'' = \gamma - \gamma'$. Dann gilt $\gamma(n) = \gamma'(n) \Leftrightarrow \gamma''(n) = 0$.
	Aufgrund der Konstruktion von $\gamma$ und $\gamma'$ ist $\gamma''$ eine Irrfahrt auf $V_3 = \set{(x_1,\dots, x_4) \in \ZZ^4 \given \sum\limits_{i =  1}^{4} x_i = 0}$.
	Das Netzwerk auf $V_3$ ist \enquote{beinahe dasselbe} wie $\ZZ^3$. Insbesondere ist $\gamma''$ auf $V_3$ transient. Insbesondere ist die Anzahl der Rückkehren in die $0$ geometrisch verteilt zu $\xi := \propE{\exists: \gamma(n) = 0}$. Also hat dieses $\mu$ EIT zu genau diesem $\xi$. 
\end{beweis}

\begin{korollar}
	Das Perkolationscluster in $\ZZ^d$ ist für $d \geq 4$ und $p > p_0 = \xi$ transient und unendlich. 
\end{korollar}
\begin{bemerkung}
	Die Aussage stimmt auch für $\ZZ^3$, der Beweis allerdings nicht.
\end{bemerkung}
\marginnote{\enquote{Es ist generell von unschätzbarem Vorteil bei mir Stochastik gehört zu haben}, Löwe 06.06.2016}








 